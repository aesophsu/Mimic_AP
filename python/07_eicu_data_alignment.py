import pandas as pd
import numpy as np
import joblib
import os

# =========================================================
# 1. é…ç½®ä¸è·¯å¾„
# =========================================================
BASE_DIR = ".."
RAW_EICU_PATH = os.path.join(BASE_DIR, "data/ap_external_validation.csv") 
SAVE_DIR = os.path.join(BASE_DIR, "data/cleaned")
MODELS_DIR = os.path.join(BASE_DIR, "models")

def run_module_07(df_input, target='pof'):
    """
    ä¼˜åŒ–ç‰ˆæ¨¡å— 07: 
    1. æ¥æ”¶é¢„è½½çš„ df_input ä»¥èŠ‚çœå†…å­˜ã€‚
    2. ä½¿ç”¨ df.copy() ç¡®ä¿æ¨¡å‹é¢„å¤„ç†ï¼ˆLog/Scaleï¼‰ä¸æ±¡æŸ“åŸå§‹æ•°æ®ã€‚
    3. è¿”å›åŸå§‹ df_input ä»¥ä¾›åç»­ Table 1 èšåˆã€‚
    """
    print("\n" + "="*75)
    print(f"ğŸš€ æ¨¡å— 07: eICU å¤šä¸­å¿ƒå¯¹é½ä¸é‡çº²ä¿®æ­£ (ç»“å±€: {target.upper()})")
    print("="*75)
    
    # ã€ä¼˜åŒ– 1ã€‘å†…å­˜ä¿æŠ¤ï¼šä½¿ç”¨å‰¯æœ¬è¿›è¡Œåç»­æ‰€æœ‰ç ´åæ€§æ“ä½œï¼ˆLog/Standardizationï¼‰
    df = df_input.copy()

    # 1. åŠ è½½ MIMIC è®­ç»ƒé˜¶æ®µèµ„äº§
    assets_path = os.path.join(MODELS_DIR, f"train_assets_{target}.pkl")
    scaler_path = os.path.join(MODELS_DIR, f"scaler_{target}.pkl") 
    
    if not os.path.exists(assets_path) or not os.path.exists(scaler_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç»“å±€ {target} çš„èµ„äº§æˆ– Scaler æ–‡ä»¶ã€‚")
        return None, None
        
    train_assets = joblib.load(assets_path)
    scaler = joblib.load(scaler_path)
    
    selected_features = train_assets['selected_features']
    mimic_medians = train_assets['medians']
    skewed_cols_to_log = train_assets['skewed_cols']

    # 2. ç»“å±€åˆ—æ˜ å°„
    target_col_map = {'pof': 'pof', 'composite_outcome': 'composite_outcome', 'mortality_28d': 'mortality_28d'}
    actual_target_col = target_col_map.get(target)

    # 3. åŸºç¡€æ¸…æ´— (ä»…åœ¨å‰¯æœ¬ä¸Šæ‰§è¡Œ)
    if 'gender' in df.columns:
        df['gender'] = df['gender'].map({'M': 1, 'F': 0, 1: 1, 0: 0}).fillna(1)
    
    if 'pao2fio2ratio_min' in df.columns:
        df['pao2fio2ratio_min'] = df['pao2fio2ratio_min'].fillna(400)

    # 4. ğŸ§ª æ ¸å¿ƒä¼˜åŒ–ï¼šåŠ¨æ€ Log1p å˜æ¢ (å‰¯æœ¬ä¸Šæ“ä½œï¼Œä¿æŠ¤ df_input)
    print(f"\nğŸª„ [1/4] æ‰§è¡Œå¯¹æ•°è¡¥ä¸å¯¹é½ (Log1p Alignment)...")
    for col in skewed_cols_to_log:
        if col in df.columns and col != 'ph_min': 
            current_med = df[col].median()
            if current_med > 3:
                df[col] = np.log1p(df[col].astype(float).clip(lower=0))
                print(f"    âœ… å·²å¯¹ {col} å®Œæˆ Log1p (å½“å‰ä¸­å€¼: {current_med:.2f})")
            else:
                print(f"    â„¹ï¸ è·³è¿‡ {col} (ä¸­å€¼ {current_med:.2f} è¾ƒå°ï¼Œæ— éœ€ Log)")

    # 5. æ„å»ºç‰¹å¾çŸ©é˜µ
    print(f"\nğŸ› ï¸ [2/4] æ„å»ºå…¨ç»´åº¦ç‰¹å¾çŸ©é˜µä»¥åŒ¹é… Scaler...")
    all_features_at_train = train_assets.get('all_features_before_lasso') 
    
    if all_features_at_train is None:
        print("âŒ é”™è¯¯ï¼štrain_assets ä¸­ç¼ºå°‘ 'all_features_before_lasso'ã€‚")
        return None, None

    X_eicu_templated = pd.DataFrame(index=df.index)
    for feat in all_features_at_train:
        if feat in df.columns:
            local_med = df[feat].median()
            fill_val = local_med if not pd.isna(local_med) else mimic_medians.get(feat, 0)
            X_eicu_templated[feat] = df[feat].fillna(fill_val)
        else:
            X_eicu_templated[feat] = mimic_medians.get(feat, 0)

    # 6. å½’ä¸€åŒ–å¯¹é½
    print(f"\nâš–ï¸ [3/4] åº”ç”¨å…¨ç»´åº¦å½’ä¸€åŒ–...")
    X_eicu_templated = X_eicu_templated[all_features_at_train]
    X_eicu_std_all = scaler.transform(X_eicu_templated)
    X_eicu_std_df = pd.DataFrame(X_eicu_std_all, columns=all_features_at_train, index=df.index)
    
    # 7. æå– LASSO æ ¸å¿ƒç‰¹å¾
    X_eicu_final_features = X_eicu_std_df[selected_features]

    # ä¿å­˜æ¨¡å‹è¾“å…¥æ–‡ä»¶
    if not os.path.exists(SAVE_DIR): os.makedirs(SAVE_DIR)
    eicu_ready_path = os.path.join(SAVE_DIR, f"eicu_for_model_{target}.csv")
    
    if actual_target_col in df.columns:
        df_ready = pd.concat([X_eicu_final_features, df[actual_target_col].rename('target')], axis=1)
        df_ready.to_csv(eicu_ready_path, index=False)
        print(f"\nâœ… ç»“å±€ {target.upper()} å¤„ç†æˆåŠŸï¼æ ·æœ¬æ•°: {len(df_ready)}")
        
        # å®¡è®¡å…³é”®ç‰¹å¾
        check_cols = [c for c in ['bun_max', 'creatinine_max', 'wbc_max'] if c in X_eicu_final_features.columns]
        if check_cols:
            print("\nğŸ“Š å…³é”®ç‰¹å¾æ ‡å‡†åŒ–åå®¡è®¡:")
            print(X_eicu_final_features[check_cols].describe().loc[['mean', 'std', 'min', 'max']])
        
        # ã€ä¼˜åŒ– 2ã€‘è¿”å›ï¼š1. åŸå§‹è¾“å…¥çš„ df_input (æœª Log), 2. æœ¬æ¬¡é€‰å‡ºçš„ç‰¹å¾
        return df_input, selected_features
    else:
        print(f"âŒ ä¸¥é‡é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç»“å±€åˆ— {actual_target_col}")
        return None, None
        
def generate_global_table1_data(snapshots):
    """
    èšåˆä¸‰ç»“å±€çš„åŸå§‹ç‰©ç†å°ºåº¦æ•°æ®ï¼Œç”Ÿæˆ Table 1 ä¸“ç”¨æ–‡ä»¶ã€‚
    snapshots: {target_name: (df_raw_original, selected_features_list)}
    """
    print("\n" + "="*60)
    print("ğŸ“¦ æ­£åœ¨æ‰§è¡Œå…¨å±€æ•°æ®èšåˆ (Table 1 ä¸“ç”¨)...")
    print("="*60)
    
    global_df = None
    
    for target, (df_raw, features) in snapshots.items():
        # 1. ç¡®å®šå½“å‰ç»“å±€æ¶‰åŠçš„åˆ—æ¸…å• (äººå£å­¦åŸºç¡€å˜é‡ + ç»“å±€æ ‡ç­¾ + æ¨¡å‹ç‰¹å¾)
        essential_cols = ['admission_age', 'gender', 'bmi', target] + list(features)
        available_cols = [c for c in essential_cols if c in df_raw.columns]
        
        # 2. æå–å­é›†å¹¶ã€é‡ç½®ç´¢å¼•ã€‘ï¼Œè¿™æ˜¯é˜²æ­¢ concat é”™ä½çš„æ ¸å¿ƒå®‰å…¨æ“ä½œ
        current_subset = df_raw[available_cols].copy().reset_index(drop=True)
        
        if global_df is None:
            # ç¬¬ä¸€æ¬¡å¾ªç¯ï¼šåˆå§‹åŒ– global_df
            global_df = current_subset
            print(f"   âœ… åˆå§‹åŒ–èšåˆè¡¨ (ç»“å±€: {target})")
        else:
            # 3. åç»­å¾ªç¯ï¼šåªåˆå¹¶æ–°å‡ºç°çš„ç‰¹å¾åˆ—æˆ–ç»“å±€åˆ—
            new_cols = [c for c in current_subset.columns if c not in global_df.columns]
            if new_cols:
                # æ˜¾å¼ä½¿ç”¨æ¨ªå‘åˆå¹¶ axis=1
                global_df = pd.concat([global_df, current_subset[new_cols]], axis=1)
                print(f"   âœ… åˆå¹¶æ–°å˜é‡ (æ¥è‡ªç»“å±€: {target}): {len(new_cols)} ä¸ª")

    # 4. æœ€ç»ˆä¿å­˜
    save_path = os.path.join(SAVE_DIR, "eicu_for_table1.csv")
    if global_df is not None:
        global_df.to_csv(save_path, index=False)
        print("-" * 60)
        print(f"âœ¨ èšåˆæˆåŠŸï¼è·¨åº“å®¡è®¡ä¸“ç”¨åŸå§‹æ•°æ®å·²ç”Ÿæˆã€‚")
        print(f"ğŸ“ æ–‡ä»¶ä½ç½®: {save_path}")
        print(f"ğŸ“Š æœ€ç»ˆè¡¨æ ¼ç»´åº¦: {global_df.shape[0]} è¡Œ x {global_df.shape[1]} åˆ—")
        print("-" * 60)

def run_all_eicu_alignment():
    """
    ä¸»ç¨‹åºå…¥å£ï¼šæ‰§è¡Œå†…å­˜ä¼˜åŒ–åçš„é¢„å¤„ç†ç®¡é“
    """
    # ã€å†…å­˜ä¼˜åŒ–æ ¸å¿ƒã€‘ï¼šå…¨è„šæœ¬ä»…åœ¨æ­¤å¤„æ‰§è¡Œä¸€æ¬¡ç£ç›˜è¯»å–
    if not os.path.exists(RAW_EICU_PATH):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° eICU åŸå§‹æ•°æ®æ–‡ä»¶: {RAW_EICU_PATH}")
        return
        
    print(f"ğŸ“– æ­£åœ¨åŠ è½½ eICU åŸå§‹å¤§æ•°æ®é›† (Memory-Optimized Loader)...")
    try:
        df_raw_master = pd.read_csv(RAW_EICU_PATH)
    except Exception as e:
        print(f"âŒ è¯»å– CSV å¤±è´¥: {e}")
        return

    targets = ['pof', 'composite_outcome', 'mortality_28d']
    snapshots = {} 
    
    # æ‰§è¡Œå¤šç»“å±€é¢„å¤„ç†å¾ªç¯
    for t in targets:
        # å°† master æ•°æ®å‰¯æœ¬ä¼ å…¥ï¼Œä¿æŠ¤åŸå§‹æ•°æ®
        result = run_module_07(df_raw_master, target=t)
        if result is not None:
            # result åŒ…å«äº† (df_input, selected_features)
            snapshots[t] = result
            
    # å¦‚æœæœ‰ä»»ä½•ç»“å±€å¤„ç†æˆåŠŸï¼Œåˆ™æ‰§è¡Œèšåˆ
    if snapshots:
        generate_global_table1_data(snapshots)
    else:
        print("âš ï¸ è­¦å‘Š: æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•ç»“å±€çš„å¿«ç…§ï¼Œè·³è¿‡èšåˆã€‚")

if __name__ == "__main__":
    run_all_eicu_alignment()
