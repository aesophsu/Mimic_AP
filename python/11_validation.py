import os
import pandas as pd
import numpy as np
import joblib
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.calibration import calibration_curve
from sklearn.metrics import brier_score_loss

# =========================================================
# 1. é…ç½®ä¸è·¯å¾„
# =========================================================
BASE_DIR = ".."
DATA_DIR = os.path.join(BASE_DIR, "data/cleaned")
MODELS_DIR = os.path.join(BASE_DIR, "models")
SAVE_DIR = os.path.join(BASE_DIR, "results/calibration")

if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR, exist_ok=True)

def run_module_12_enhanced_audit(target='pof'):
    print("="*75)
    print(f"ğŸ”¬ æ¨¡å— 12: ä¸´åºŠæ ¡å‡†å®¡è®¡ä¸æ¯”å€¼æ¯” (OR) åˆ†æ | ç»“å±€: {target.upper()}")
    print("="*75)

    # 1. åŠ è½½ eICU å¤–éƒ¨éªŒè¯æ•°æ®ä¸æ¨¡å‹å­—å…¸
    eicu_path = os.path.join(DATA_DIR, f"eicu_for_model_{target}.csv")
    model_dict_path = os.path.join(MODELS_DIR, f"all_models_{target}.pkl")
    
    if not (os.path.exists(eicu_path) and os.path.exists(model_dict_path)):
        print(f"âŒ é”™è¯¯ï¼šç¼ºå°‘ {target} çš„éªŒè¯æ•°æ®æˆ–æ¨¡å‹åŒ…ã€‚")
        return

    df_eicu = pd.read_csv(eicu_path)
    X_eicu = df_eicu.drop('target', axis=1)
    y_eicu = df_eicu['target']
    models_dict = joblib.load(model_dict_path)

    # ---------------------------------------------------------
    # A. æ¦‚ç‡æ ¡å‡†å®¡è®¡ (Calibration Curve)
    # ---------------------------------------------------------
    print("\nğŸš© [Step 1] æ­£åœ¨æ‰§è¡Œå¤šæ¨¡å‹æ ¡å‡†å®¡è®¡ (Probability Calibration):")
    plt.figure(figsize=(9, 8), dpi=150)
    plt.plot([0, 1], [0, 1], "k--", label="Perfect Calibration (Ideal)", alpha=0.5)
    
    calibration_metrics = []

    for name, model in models_dict.items():
        # è·å–å¤–éƒ¨éªŒè¯é›†é¢„æµ‹æ¦‚ç‡
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ˜¯ Pipeline åˆ™ä½¿ç”¨ .values
        X_input = X_eicu.values if hasattr(model, 'named_steps') else X_eicu
        y_prob = model.predict_proba(X_input)[:, 1]
        
        # è®¡ç®—æ ¡å‡†æ›²çº¿ä¸ Brier åˆ†æ•°
        prob_true, prob_pred = calibration_curve(y_eicu, y_prob, n_bins=10)
        brier = brier_score_loss(y_eicu, y_prob)
        
        # ç»˜å›¾
        plt.plot(prob_pred, prob_true, "s-", markersize=4, label=f"{name} (Brier: {brier:.4f})")
        calibration_metrics.append((name, brier))
        print(f"  - {name:<20} | Brier Score = {brier:.4f}")

    plt.title(f"External Calibration Curve: {target.upper()}", fontsize=14)
    plt.xlabel("Predicted Risk (Expected Probability)")
    plt.ylabel("Observed Outcome (Actual Probability)")
    plt.legend(loc="lower right", frameon=True)
    plt.grid(alpha=0.3)
    
    cal_img_path = os.path.join(SAVE_DIR, f"calibration_audit_{target}.png")
    plt.savefig(cal_img_path, bbox_inches='tight')
    print(f"\nğŸ“Š æ ¡å‡†å®¡è®¡å›¾å·²ä¿å­˜è‡³: {cal_img_path}")

    # ---------------------------------------------------------
    # B. æ¯”å€¼æ¯”åˆ†æ (Odds Ratio for Nomogram)
    # ---------------------------------------------------------
    if "Logistic Regression" in models_dict:
        print(f"\nğŸš© [Step 2] æå– {target.upper()} ä¸´åºŠé£é™©æƒé‡ (Odds Ratios):")
        lr_wrapper = models_dict["Logistic Regression"]
        
        # --- ä¿®å¤ä»£ç å¼€å§‹ ---
        # 1. å¤„ç† CalibratedClassifierCV åŒ…è£…
        if hasattr(lr_wrapper, 'calibrated_classifiers_'):
            # æå–ç¬¬ä¸€ä¸ªäº¤å‰éªŒè¯æŠ˜å ä¸­çš„åŸºæ¨¡å‹
            raw_model = lr_wrapper.calibrated_classifiers_[0].estimator
        else:
            raw_model = lr_wrapper

        # 2. å¤„ç† Pipeline åŒ…è£…
        if hasattr(raw_model, 'named_steps'):
            final_lr = raw_model.named_steps['model']
        else:
            final_lr = raw_model

        # 3. æå–ç³»æ•° (ç¡®ä¿å®ƒæœ‰ coef_ å±æ€§)
        if hasattr(final_lr, 'coef_'):
            coefs = final_lr.coef_[0]
            # --- ä¿®å¤ä»£ç ç»“æŸ ---
            
            or_values = np.exp(coefs)
            
            or_df = pd.DataFrame({
                'Feature': X_eicu.columns,
                'Beta_Coef': coefs,
                'Odds_Ratio': or_values
            }).sort_values(by='Odds_Ratio', ascending=False)

            # ä¿å­˜å¹¶æ‰“å°ç»“æœ
            or_path = os.path.join(SAVE_DIR, f"odds_ratio_{target}.csv")
            or_df.to_csv(or_path, index=False)
            
            for _, row in or_df.iterrows():
                impact = "ğŸš© å±é™©å› ç´ " if row['Odds_Ratio'] > 1 else "âœ… ä¿æŠ¤å› ç´ "
                print(f"  - {row['Feature']:<20} | OR = {row['Odds_Ratio']:>6.2f} | {impact}")
        else:
            print("  âš ï¸ æ— æ³•æå–ç³»æ•°ï¼šæ¨¡å‹ä¸åŒ…å« coef_ å±æ€§ã€‚")

    # ---------------------------------------------------------
    # C. ä¸´åºŠè§£é‡Šå»ºè®®
    # ---------------------------------------------------------
    print("\nğŸ“ [Step 3] ä¸´åºŠè§£é‡Šç¬”è®° (Audit Notes):")
    best_brier = min(calibration_metrics, key=lambda x: x[1])
    print(f"  ğŸ’¡ é¢„æµ‹å¯é æ€§ï¼š{best_brier[0]} å…·æœ‰æœ€ä½çš„ Brier åˆ†æ•°ï¼Œä»£è¡¨å…¶æ¦‚ç‡ä¼°è®¡æœ€ç²¾å‡†ã€‚")
    print("  ğŸ’¡ è¯ºè«å›¾è½¬åŒ–ï¼šLogistic Regression çš„ OR å€¼åæ˜ äº†å•å•ä½ç‰¹å¾å˜åŒ–å¯¹å‘ç—…èƒœç®—çš„è´¡çŒ®ã€‚")
    print("  ğŸ’¡ é£é™©æ ¡å‡†ï¼šè‹¥æ›²çº¿åœ¨ç†æƒ³çº¿ä¸Šæ–¹ï¼Œä»£è¡¨æ¨¡å‹åœ¨å¤–éƒ¨äººç¾¤ä¸­å€¾å‘äºä½ä¼°é£é™©ï¼ˆUnder-predictionï¼‰ã€‚")

    plt.show()

if __name__ == "__main__":
    # é’ˆå¯¹æ‰€æœ‰ç»“å±€æ‰§è¡Œå®¡è®¡
    for t in ['pof', 'composite_outcome', 'mortality_28d']:
        run_module_12_enhanced_audit(t)
