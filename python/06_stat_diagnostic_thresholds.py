import os
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, confusion_matrix, precision_score, recall_score, f1_score

# =========================================================
# é…ç½®è·¯å¾„
# =========================================================
BASE_DIR = ".."
MODEL_DIR = os.path.join(BASE_DIR, "models")
SAVE_DIR = os.path.join(BASE_DIR, "results")
if not os.path.exists(SAVE_DIR): os.makedirs(SAVE_DIR)

def run_module_06():
    print("="*60)
    print("ğŸš€ è¿è¡Œæ¨¡å— 06: è®¡ç®—æœ€ä½³æˆªæ–­å€¼ä¸ä¸´åºŠè¯Šæ–­æ•ˆèƒ½")
    print("="*60)

    # 1. åŠ è½½æ¨¡å‹ä¸æµ‹è¯•æ•°æ®
    # æˆ‘ä»¬é€‰æ‹©è¡¨ç°æœ€å¥½çš„ SVM æ¨¡å‹
    all_models = joblib.load(os.path.join(MODEL_DIR, "all_models.pkl"))
    model = all_models['SVM']
    
    # åŠ è½½æµ‹è¯•é›†
    X_test, y_test = joblib.load(os.path.join(MODEL_DIR, "test_data_main.pkl"))
    X_test_np = X_test.values if hasattr(X_test, 'values') else X_test

    # 2. è·å–é¢„æµ‹æ¦‚ç‡
    y_probs = model.predict_proba(X_test_np)[:, 1]

    # 3. è®¡ç®— ROC æ›²çº¿æ•°æ®
    fpr, tpr, thresholds = roc_curve(y_test, y_probs)

    # 4. å¯»æ‰¾çº¦ç™»æŒ‡æ•°æœ€å¤§å€¼çš„ç´¢å¼• (Youden Index = Sensitivity + Specificity - 1)
    # çº¦ç™»æŒ‡æ•°æœ€å¤§ç‚¹å³ä¸ºæœ€ä½³æˆªæ–­å€¼
    youden_index = tpr + (1 - fpr) - 1
    best_idx = np.argmax(youden_index)
    best_threshold = thresholds[best_idx]
    
    # 5. åŸºäºæœ€ä½³æˆªæ–­å€¼ç”ŸæˆäºŒåˆ†ç±»é¢„æµ‹
    y_pred = (y_probs >= best_threshold).astype(int)

    # 6. è®¡ç®—è¯¦ç»†æ€§èƒ½æŒ‡æ ‡
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    
    sensitivity = tp / (tp + fn)      # çµæ•åº¦ (Recall)
    specificity = tn / (tn + fp)      # ç‰¹å¼‚åº¦
    ppv = tp / (tp + fp)              # é˜³æ€§é¢„æµ‹å€¼ (Precision)
    npv = tn / (tn + fn)              # é˜´æ€§é¢„æµ‹å€¼
    accuracy = (tp + tn) / (tp + tn + fp + fn)
    f1 = f1_score(y_test, y_pred)

    # 7. æ‰“å°ç»“æœ
    print(f"ğŸ¯ æœ€ä½³æ¦‚ç‡æˆªæ–­å€¼ (Best Threshold): {best_threshold:.4f}")
    print("-" * 30)
    print(f"âœ… çµæ•åº¦ (Sensitivity):   {sensitivity:.4f}")
    print(f"âœ… ç‰¹å¼‚åº¦ (Specificity):   {specificity:.4f}")
    print(f"âœ… é˜³æ€§é¢„æµ‹å€¼ (PPV):       {ppv:.4f}")
    print(f"âœ… é˜´æ€§é¢„æµ‹å€¼ (NPV):       {npv:.4f}")
    print(f"âœ… æ€»å‡†ç¡®ç‡ (Accuracy):    {accuracy:.4f}")
    print(f"âœ… F1 åˆ†æ•° (F1-Score):     {f1:.4f}")

    # 8. ä¿å­˜è¯Šæ–­æŒ‡æ ‡åˆ° CSV
    performance_metrics = {
        'Metric': ['Best Threshold', 'Sensitivity', 'Specificity', 'PPV', 'NPV', 'Accuracy', 'F1-Score'],
        'Value': [best_threshold, sensitivity, specificity, ppv, npv, accuracy, f1]
    }
    metrics_df = pd.DataFrame(performance_metrics)
    metrics_path = os.path.join(SAVE_DIR, "diagnostic_performance_svm.csv")
    metrics_df.to_csv(metrics_path, index=False)

    # --------------------------------------------------------
    # ç»˜åˆ¶å¸¦ Cut-off ç‚¹çš„ ROC æ›²çº¿
    # --------------------------------------------------------
    plt.figure(figsize=(8, 7))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {best_threshold:.2f})')
    plt.scatter(fpr[best_idx], tpr[best_idx], color='red', marker='o', s=100, 
                label=f'Best Cut-off: {best_threshold:.2f}')
    
    plt.annotate(f'Cut-off: {best_threshold:.2f}\n(Sen: {sensitivity:.2f}, Spe: {specificity:.2f})',
                 xy=(fpr[best_idx], tpr[best_idx]), xytext=(fpr[best_idx]+0.1, tpr[best_idx]-0.2),
                 arrowprops=dict(facecolor='black', shrink=0.05),
                 fontsize=10)

    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate (1 - Specificity)')
    plt.ylabel('True Positive Rate (Sensitivity)')
    plt.title('ROC Curve with Optimal Cut-off')
    plt.legend(loc="lower right")
    plt.grid(alpha=0.3)
    
    plot_path = os.path.join(BASE_DIR, "models/plots/05_ROC_with_Cutoff.png")
    plt.savefig(plot_path, dpi=300)
    print(f"\nğŸ“ˆ ROC æˆªæ–­å€¼å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³: {plot_path}")
    print(f"âœ… æŒ‡æ ‡æ•°æ®å·²ä¿å­˜è‡³: {metrics_path}")

if __name__ == "__main__":
    run_module_06()
