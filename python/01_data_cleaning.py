import os
import numpy as np
import pandas as pd

# =========================================================
# 1. é…ç½®ä¸è·¯å¾„
# =========================================================
BASE_DIR = ".."
INPUT_PATH = os.path.join(BASE_DIR, "data/ap_final_analysis_cohort.csv")
SAVE_DIR = os.path.join(BASE_DIR, "data/cleaned")

# ç¼ºå¤±ç‡é—¨æ§›ï¼šè¶…è¿‡ 30% åˆ™å‰”é™¤ï¼ˆé™¤éåœ¨ç™½åå•ä¸­ï¼‰
MISSING_THRESHOLD = 0.3 

if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR)

def run_module_01():
    print("="*60)
    print("ğŸš€ è¿è¡Œæ¨¡å— 01: çŠ¶æ€æ ‡è®°ã€28å¤©æ­»äº¡å®šä¹‰ä¸ç‰¹å¾æ¸…æ´—")
    print("="*60)
    
    if not os.path.exists(INPUT_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {INPUT_PATH}")
        return
    
    df_raw = pd.read_csv(INPUT_PATH)
    df = df_raw.copy()
    print(f"ğŸ“Š åŸå§‹æ•°æ®è¯»å–æˆåŠŸ: {df.shape[0]} è¡Œ, {df.shape[1]} åˆ—")

    # =========================================================
    # 2. ç²¾å‡†å®šä¹‰ 28å¤©æ­»äº¡ç‡ (Primary Outcome)
    # =========================================================
    # è½¬æ¢æ—¶é—´æ ¼å¼
    df['intime'] = pd.to_datetime(df['intime'])
    df['deathtime'] = pd.to_datetime(df['deathtime'])
    df['dod'] = pd.to_datetime(df['dod'])

    # æ ‡è®°ä½é™¢æ­»äº¡ä¸æ€»æ­»äº¡ (åŸºç¡€æ ‡è®°)
    df['hosp_mortality'] = df['deathtime'].notnull().astype(int)
    df['overall_mortality'] = df['dod'].notnull().astype(int)

    # è®¡ç®—å…¥ ICU åˆ°æ­»äº¡çš„å¤©æ•°
    # å– deathtime å’Œ dod ä¸­è¾ƒæ—©çš„ä¸€ä¸ªä½œä¸ºæ­»äº¡å‘ç”Ÿæ—¶é—´
    death_timestamp = df[['deathtime', 'dod']].min(axis=1)
    days_to_death = (death_timestamp - df['intime']).dt.total_seconds() / (24 * 3600)

    # æ ¸å¿ƒæŒ‡æ ‡ï¼š28å¤©æ­»äº¡ç‡ (1=28å¤©å†…æ­»äº¡, 0=å­˜æ´»æˆ–28å¤©åæ­»äº¡)
    df['mortality_28d'] = ((days_to_death >= 0) & (days_to_death <= 28)).astype(int)
    
    print(f"âœ… ç»“å±€æ ‡è®°å®Œæˆ:")
    print(f"   - 28å¤©å†…æ­»äº¡: {df['mortality_28d'].sum()} ä¾‹")
    print(f"   - ä½é™¢æœŸé—´æ­»äº¡: {df['hosp_mortality'].sum()} ä¾‹")
    print(f"   - éšè®¿æ€»æ­»äº¡: {df['overall_mortality'].sum()} ä¾‹")

    # =========================================================
    # 3. æ ¸å¿ƒä¿æŠ¤ç™½åå• (White List)
    # =========================================================
    # å³ä½¿ç¼ºå¤±ç‡é«˜ï¼Œä¹Ÿå¿…é¡»ä¿ç•™çš„ç‰¹å¾
    outcome_labels = ['mortality_28d', 'hosp_mortality', 'overall_mortality', 
                      'pof', 'renal_pof', 'resp_pof', 'cv_pof']
    
    clinical_soul_cols = [
        'lactate_max', 'pao2fio2ratio_min',
        'lipase_max', 'lab_amylase_max', 'creatinine_max'
    ]
    
    id_time_cols = ['subject_id', 'hadm_id', 'stay_id', 'intime', 'admittime']
    
    white_list = outcome_labels + clinical_soul_cols + id_time_cols

    # =========================================================
    # 4. ç¼ºå¤±ç‡è¿‡æ»¤ (Feature Filtering)
    # =========================================================
    missing_pct = df.isnull().mean()
    high_missing_cols = missing_pct[missing_pct > MISSING_THRESHOLD].index.tolist()
    
    # ç¡®å®šå‰”é™¤åå•ï¼šåœ¨é«˜ç¼ºå¤±åå•ä¸­ï¼Œä¸”ä¸åœ¨ç™½åå•å†…
    # æ³¨æ„ï¼šåŸå§‹çš„ deathtime å’Œ dod ä¼šåœ¨è¿™é‡Œè¢«å‰”é™¤ï¼Œå› ä¸ºæˆ‘ä»¬å·²æå–äº† mortality_28d
    cols_to_drop = [c for c in high_missing_cols if c not in white_list]
    df_filtered = df.drop(columns=cols_to_drop)

    # =========================================================
    # 5. å•ä½æ ¡å‡†ä¸ç›–å¸½å¤„ç† (Table 1 Ready)
    # =========================================================
    # Fibrinogen å•ä½æ ¡å‡† (mg/dL)
    if 'fibrinogen_max' in df_filtered.columns:
        median_fib = df_filtered['fibrinogen_max'].median()
        if not pd.isna(median_fib) and median_fib < 50:
            df_filtered['fibrinogen_max'] = df_filtered['fibrinogen_max'] * 100

    df_table1 = df_filtered.copy()
    numeric_cols = df_table1.select_dtypes(include=[np.number]).columns
    
    # æ’é™¤ä¸éœ€è¦æˆªæ–­çš„åˆ— (ID, ç»“å±€, äºŒå…ƒå˜é‡)
    skip_clip = white_list + ['gender_num', 'alcoholic_ap', 'biliary_ap', 
                             'hyperlipidemic_ap', 'drug_induced_ap', 'vaso_flag', 'mechanical_vent_flag']
    
    for col in numeric_cols:
        if col in df_table1.columns and col not in skip_clip:
            df_table1[col] = df_table1[col].clip(df_table1[col].quantile(0.01), 
                                                 df_table1[col].quantile(0.99))

    # =========================================================
    # 6. ç‰¹å¾è‡ªæ£€æŠ¥å‘Šä¸æ¸…å•æ˜¾ç¤º
    # =========================================================
    print("-" * 60)
    print("ğŸ“‹ ç‰¹å¾è‡ªæ£€æŠ¥å‘Š")
    print("-" * 60)
    print(f"ğŸ”¹ åŸå§‹æ€»åˆ—æ•°: {len(df_raw.columns)}")
    print(f"ğŸ”¹ å‰”é™¤åˆ—æ•°: {len(cols_to_drop)}")
    print(f"ğŸ”¹ æœ€ç»ˆä¿ç•™åˆ—æ•°: {len(df_table1.columns)}")
    
    if cols_to_drop:
        print(f"ğŸ—‘ï¸ å·²å‰”é™¤ç‰¹å¾ (ç¼ºå¤±ç‡ > {MISSING_THRESHOLD*100}%):")
        for c in sorted(cols_to_drop):
            print(f"   - {c:<25} (ç¼ºå¤±ç‡: {df_raw[c].isnull().mean():.2%})")

    # æ‰“å°æœ€ç»ˆæ¸…å•
    final_cols = sorted(df_table1.columns.tolist())
    print("-" * 60)
    print("ğŸ’ æœ€ç»ˆä¿ç•™ç‰¹å¾æ¸…å•ï¼š")
    for i in range(0, len(final_cols), 3):
        row = final_cols[i:i+3]
        print("".join([f"{col:<30}" for col in row]))

    # ä¿å­˜æ–‡ä»¶
    table1_path = os.path.join(SAVE_DIR, "mimic_for_table1.csv")
    df_table1.to_csv(table1_path, index=False)
    
    print("-" * 60)
    print(f"âœ… æ¨¡å— 01 å®Œæˆ! å¹²å‡€æ•°æ®å·²å­˜è‡³: {table1_path}")
    print("="*60)

if __name__ == "__main__":
    run_module_01()
