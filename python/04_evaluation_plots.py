import os
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, brier_score_loss
import shap
import warnings

# å±è”½ä¸å¿…è¦çš„ UserWarning å¹²æ‰°
warnings.filterwarnings('ignore', category=UserWarning)

# é…ç½®è·¯å¾„
MODEL_DIR = "../models"
FIG_DIR = "../figures"
if not os.path.exists(FIG_DIR): os.makedirs(FIG_DIR)

def calculate_net_benefit(y_true, y_prob, thresh):
    y_pred = (y_prob >= thresh).astype(int)
    tp = np.sum((y_pred == 1) & (y_true == 1))
    fp = np.sum((y_pred == 1) & (y_true == 0))
    n = len(y_true)
    if thresh >= 1.0 or thresh <= 0: return 0
    return (tp / n) - (fp / n) * (thresh / (1 - thresh))

def run_module_04_debug_version():
    print("="*70)
    print("ðŸš€ è¿è¡Œæ¨¡å— 04 å¢žå¼ºå®¡è®¡ç‰ˆ: å¯è§†åŒ–ä¸Ž SHAP è§£é‡Š")
    print("="*70)

    # 1. åŠ è½½èµ„äº§å¹¶æ‰“å°å®¡è®¡ä¿¡æ¯
    print("ðŸ“‚ [Step 1/4] æ­£åœ¨åŠ è½½æ¨¡åž‹ä¸Žæ•°æ®èµ„äº§...")
    try:
        all_models = joblib.load(os.path.join(MODEL_DIR, "all_models.pkl"))
        selected_features = joblib.load(os.path.join(MODEL_DIR, "selected_features.pkl"))
        
        X_test, y_test = joblib.load(os.path.join(MODEL_DIR, "test_data_main.pkl"))
        X_test_np = X_test.values if hasattr(X_test, 'values') else X_test

        # [æ–°å¢ž] åŠ è½½äºšç»„æ•°æ®ç”¨äºŽå¯¹æ¯”å®¡è®¡
        X_sub, y_sub = joblib.load(os.path.join(MODEL_DIR, "test_data_sub.pkl"))
        X_sub_np = X_sub.values if hasattr(X_sub, 'values') else X_sub

        print(f"   âœ… åŠ è½½æˆåŠŸ: åŒ…å« {len(all_models)} ä¸ªæ¨¡åž‹")
        print(f"   âœ… ç‰¹å¾åˆ—è¡¨: {selected_features}")
        print(f"   âœ… æµ‹è¯•é›†ç»´åº¦: {X_test_np.shape}, POF æµè¡ŒçŽ‡: {np.mean(y_test):.2%}")
    except Exception as e:
        print(f"   âŒ åŠ è½½å¤±è´¥: {e}")
        return

    # --------------------------------------------------------
    # [å›¾ 1] å…¨æ¨¡åž‹ ROC å¯¹æ¯”
    # --------------------------------------------------------
    print("\nðŸ“ˆ [Step 2/4] æ­£åœ¨ç»˜åˆ¶å¤šæ¨¡åž‹ ROC æ›²çº¿å¹¶å®¡è®¡ AUC...")
    plt.figure(figsize=(9, 8))
    # --------------------------------------------------------
    # [Step 2] åŒæ­¥æ¨¡å— 03 çš„å®¡è®¡æ•°æ®
    # --------------------------------------------------------
    # å¡«å…¥æ¨¡å— 03 æ‰“å°çš„ Main AUC (95% CI)
    ci_data = {
        "XGBoost": "0.831 (0.771-0.882)",
        "SVM": "0.839 (0.782-0.888)",
        "Random Forest": "0.834 (0.777-0.885)",
        "Logistic Regression": "0.833 (0.775-0.884)",
        "Decision Tree": "0.818 (0.760-0.873)"
    }

    # [æ–°å¢ž] å¡«å…¥æ¨¡å— 03 æ‰“å°çš„ No-Renal AUC (95% CI)
    sub_ci_data = {
        "XGBoost": "0.752 (0.645-0.853)",
        "SVM": "0.774 (0.656-0.880)",
        "Random Forest": "0.760 (0.647-0.861)",
        "Logistic Regression": "0.768 (0.656-0.862)",
        "Decision Tree": "0.745 (0.631-0.852)"
    }

    for name, clf in all_models.items():
        # å¼ºåˆ¶ä½¿ç”¨ numpy æ•°ç»„é¢„æµ‹ï¼Œæ¶ˆé™¤è­¦å‘Š
        y_prob = clf.predict_proba(X_test_np)[:, 1]
        fpr, tpr, _ = roc_curve(y_test, y_prob)
        roc_auc = auc(*roc_curve(y_test, y_prob)[:2])
    
        # [æ–°å¢ž] è®¡ç®—äºšç»„æ€§èƒ½
        y_prob_sub = clf.predict_proba(X_sub_np)[:, 1]
        roc_auc_sub = auc(*roc_curve(y_sub, y_prob_sub)[:2])
    
        # ä¿®æ”¹æ‰“å°ä¿¡æ¯ï¼Œå¢žåŠ  Sub-AUC å®¡è®¡
        print(f"   ðŸ” æ¨¡åž‹å®¡è®¡: {name:<20} | Test AUC: {roc_auc:.4f} | Sub-AUC: {roc_auc_sub:.4f}")
    
        display_label = f"{name}: {ci_data.get(name, f'{roc_auc:.3f}')}"
        plt.plot(fpr, tpr, lw=2, label=display_label)

    plt.plot([0, 1], [0, 1], 'k--', alpha=0.2)
    plt.xlabel('False Positive Rate', fontsize=12)
    plt.ylabel('True Positive Rate', fontsize=12)
    plt.title('Predictive Performance Comparison', fontsize=14, fontweight='bold')
    plt.legend(loc='lower right', fontsize=9)
    plt.grid(alpha=0.2)
    plt.savefig(os.path.join(FIG_DIR, "01_ROC_Comparison.png"), dpi=300)
    plt.close()

    # --------------------------------------------------------
    # [å›¾ 2] SHAP è§£é‡Š (é’ˆå¯¹ SVM - å…¨æ ·æœ¬ç²¾ç¡®ç‰ˆ + è‡ªåŠ¨ç¼“å­˜)
    # --------------------------------------------------------
    print("\nðŸ§ª [Step 3/4] æ­£åœ¨å¤„ç† SVM SHAP è§£é‡Š (å…¨æ ·æœ¬ç²¾ç¡®å®¡è®¡)...")
    SHAP_CACHE_PATH = os.path.join(MODEL_DIR, "svm_shap_values_full.pkl")

    try:
        # 1. å°è¯•åŠ è½½çŽ°æœ‰çš„ç¼“å­˜
        if os.path.exists(SHAP_CACHE_PATH):
            print(f"   â™»ï¸ æ£€æµ‹åˆ°ç¼“å­˜ï¼Œæ­£åœ¨åŠ è½½é¢„è®¡ç®—çš„å…¨æ ·æœ¬ SHAP å€¼...")
            shap_values = joblib.load(SHAP_CACHE_PATH)
        else:
            print("   â³ æœªæ£€æµ‹åˆ°ç¼“å­˜ï¼Œå¯åŠ¨å…¨æ ·æœ¬ SVM SHAP è®¡ç®—...")
            print("   ðŸ“¢ æ³¨æ„ï¼šåŽ»æŽ‰æ ·æœ¬é™åˆ¶åŽè®¡ç®—åŽ‹åŠ›è¾ƒå¤§ï¼Œé¢„è®¡è€—æ—¶ 20-40 åˆ†é’Ÿï¼Œè¯·ä¿æŒç¨‹åºè¿è¡Œã€‚")
            
            svm_model = all_models['SVM']
            
            # å®šä¹‰é¢„æµ‹æ¦‚çŽ‡å‡½æ•°
            def svm_predict(data):
                return svm_model.predict_proba(data)[:, 1]

            # åŽ»æŽ‰ max_samples é™åˆ¶ï¼Œä½¿ç”¨å®Œæ•´çš„ X_test_np ä½œä¸ºèƒŒæ™¯å‚è€ƒ
            # è¿™æ ·è®¡ç®—å‡ºçš„ SHAP å€¼æœ€å…·å­¦æœ¯ä¸¥è°¨æ€§
            masker = shap.maskers.Independent(X_test_np) 
            
            explainer = shap.Explainer(svm_predict, masker)
            
            # æ‰§è¡Œè®¡ç®— (silent=True å±è”½è¿›åº¦æ¡åˆ·å±ï¼Œé˜²æ­¢æŽ§åˆ¶å°å¡æ­»)
            shap_values = explainer(X_test_np, silent=True)
            
            # ä¿å­˜ç»“æžœåˆ°æœ¬åœ°
            joblib.dump(shap_values, SHAP_CACHE_PATH)
            print(f"   ðŸ’¾ å…¨æ ·æœ¬ SHAP è®¡ç®—å®Œæˆå¹¶å·²æ°¸ä¹…ä¿å­˜è‡³: {SHAP_CACHE_PATH}")

        # 2. ç»˜å›¾
        plt.figure(figsize=(12, 10)) # ç•¥å¾®å¢žåŠ é«˜åº¦ä»¥é€‚åº”æ›´å¤šç‰¹å¾
        shap.plots.beeswarm(shap_values, max_display=12, show=False)
        plt.title('SVM SHAP Summary: Global Impact on POF Risk (Full Audit)', fontsize=14, fontweight='bold')
        plt.xlabel("SHAP Value (Impact on POF Probability)")
        
        plt.tight_layout()
        plt.savefig(os.path.join(FIG_DIR, "02_SHAP_Summary_SVM_Full.png"), dpi=300)
        plt.close()
        print("   âœ… ç²¾ç¡®ç‰ˆ SHAP æ‘˜è¦å›¾å·²ç”Ÿæˆ: 02_SHAP_Summary_SVM_Full.png")

    except Exception as e:
        print(f"   âš ï¸ SHAP æ¨¡å—è¿è¡Œå¤±è´¥: {e}")

    # --------------------------------------------------------
    # Step 4: å…¨æ¨¡åž‹ DCA ä¸´åºŠä»·å€¼å®¡è®¡ (ä¿®å¤ç´¢å¼•é”™è¯¯å¹¶å…¨é‡åŒ–)
    # --------------------------------------------------------
    print("\nâš–ï¸ [Step 4/4] æ­£åœ¨æ‰§è¡Œå…¨æ¨¡åž‹ DCA ä¸´åºŠä»·å€¼å®¡è®¡...")
    plt.figure(figsize=(10, 8))
    thresholds = np.arange(0.01, 0.81, 0.01)
    
    # åŸºç¡€å‚ç…§çº¿: Treat All (æ‰€æœ‰äººéƒ½è§†ä¸ºé«˜å±)
    prev = np.mean(y_test)
    nb_all = [prev - (1 - prev) * (t / (1 - t)) for t in thresholds]
    
    model_windows = {}
    colors = ['#d62728', '#1f77b4', '#2ca02c', '#ff7f0e', '#9467bd']

    for (name, clf), color in zip(all_models.items(), colors):
        y_prob = clf.predict_proba(X_test_np)[:, 1]
        nb_model = [calculate_net_benefit(y_test, y_prob, t) for t in thresholds]
        
        # ç²¾ç¡®è®¡ç®—èŽ·ç›Šçª—å£: Net Benefit > Treat All ä¸” Net Benefit > 0
        better_than_all = [t for t, nb, nba in zip(thresholds, nb_model, nb_all) if nb > nba and nb > 0]
        
        if better_than_all:
            win_min, win_max = min(better_than_all), max(better_than_all)
            window_str = f"{win_min:.1%} - {win_max:.1%}"
            model_windows[name] = window_str
            print(f"   âœ… {name:<20} | èŽ·ç›Šçª—å£: {window_str}")
        else:
            model_windows[name] = "No Benefit"
            print(f"   âš ï¸ {name:<20} | æœªæ£€æµ‹åˆ°èŽ·ç›ŠåŒºé—´")

        plt.plot(thresholds, nb_model, lw=2, color=color, label=f"{name} ({model_windows[name]})")

    # ç»˜åˆ¶å‚è€ƒè™šçº¿
    plt.plot(thresholds, nb_all, color='black', linestyle=':', alpha=0.4, label='Treat All')
    plt.axhline(y=0, color='gray', lw=1, label='Treat None')
    
    plt.ylim(-0.05, prev + 0.1)
    plt.xlim(0, 0.8)
    plt.xlabel('Risk Threshold Probability (Cut-off)')
    plt.ylabel('Net Benefit')
    plt.title('Decision Curve Analysis: Comparative Utility', fontsize=14, fontweight='bold')
    plt.legend(loc='upper right', fontsize=9)
    plt.grid(alpha=0.2)
    plt.savefig(os.path.join(FIG_DIR, "03_DCA_Full_Comparison.png"), dpi=300)
    plt.close()
    # --------------------------------------------------------
    # æ€»ç»“è¾“å‡º (Table 2 ç»ˆæžç‰ˆ)
    # --------------------------------------------------------
    print("\n" + "="*115)
    print(f"{'Algorithm':<20} | {'Main AUC (95% CI)':<25} | {'No-Renal AUC (95% CI)':<25} | {'DCA Window':<15}")
    print("-" * 115)
    for name in all_models.keys():
        main_val = ci_data.get(name, "N/A")
        sub_val = sub_ci_data.get(name, "N/A")
        window = model_windows.get(name, "N/A")
        print(f"{name:<20} | {main_val:<25} | {sub_val:<25} | {window:<15}")
    print("="*115)
    print(f"ðŸŽ‰ æ¨¡å— 04 è¿è¡ŒæˆåŠŸï¼å›¾è¡¨ä½äºŽ: {FIG_DIR}")
    
if __name__ == "__main__":
    run_module_04_debug_version()
