import os
import pandas as pd
import numpy as np
import joblib
from scipy import stats

# =========================================================
# é…ç½®è·¯å¾„
# =========================================================
BASE_DIR = ".."
# å…³é”®ä¿®æ”¹ï¼šè¯»å–æ¸…æ´—åã€æ ‡å‡†åŒ–å‰çš„åŸå§‹æ•°æ®é›† (è¯·æ ¹æ®ä½ å®é™…æ–‡ä»¶åä¿®æ”¹)
RAW_DATA_PATH = os.path.join(BASE_DIR, "data/cleaned/mimic_for_model.csv") 
SAVE_DIR = os.path.join(BASE_DIR, "results")
MODEL_DIR = os.path.join(BASE_DIR, "models")

if not os.path.exists(SAVE_DIR): os.makedirs(SAVE_DIR)

def run_module_05_raw_full():
    print("="*70)
    print("ğŸš€ è¿è¡Œæ¨¡å— 05: å…¨é‡åŸå§‹æ•°å€¼åŸºçº¿ç»Ÿè®¡ (è®ºæ–‡ Table 1 æ ‡å‡†ç‰ˆ)")
    print("="*70)

    # 1. åŠ è½½æ•°æ®
    if not os.path.exists(RAW_DATA_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°åŸå§‹æ•°æ®æ–‡ä»¶ {RAW_DATA_PATH}")
        return
    
    df = pd.read_csv(RAW_DATA_PATH)
    
    # 2. æ ¸å¿ƒç‰¹å¾å¯¹é½
    try:
        selected_features = joblib.load(os.path.join(MODEL_DIR, "selected_features.pkl"))
        print(f"âœ… å·²åŒæ­¥æ¨¡å‹æ ¸å¿ƒç‰¹å¾: {len(selected_features)} ä¸ª")
    except:
        selected_features = []
        print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° selected_features.pklï¼Œå°†ä½¿ç”¨é»˜è®¤åˆ—å")

    # å®šä¹‰ç›®æ ‡å˜é‡å’Œåˆ†ç»„ N å€¼
    target = 'pof'
    n_total = len(df)
    n_pof = int(df[target].sum())
    n_non_pof = n_total - n_pof
    
    print(f"ğŸ“Š åˆ†ææ ·æœ¬æ€»é‡: {n_total} (Non-POF: {n_non_pof}, POF: {n_pof})")

    # å®šä¹‰å˜é‡åˆ†ç±»
    # è¿ç»­å˜é‡ï¼šäººå£å­¦ + æ¨¡å‹æ ¸å¿ƒæŒ‡æ ‡
    continuous_vars = ['admission_age', 'weight_admit', 'bmi'] + [f for f in selected_features if f not in ['admission_age']]
    # åˆ†ç±»å˜é‡ï¼šæ€§åˆ« + æ—¢å¾€å²
    categorical_vars = ['gender', 'heart_failure', 'chronic_kidney_disease', 'malignant_tumor']

    table1_data = []

    # --- A. è¿ç»­å˜é‡å¤„ç† (åŸå§‹æ•°å€¼) ---
    for var in [v for v in continuous_vars if v in df.columns]:
        g0 = df[df[target] == 0][var].dropna()
        g1 = df[df[target] == 1][var].dropna()
        
        # ç»Ÿè®¡æè¿°é€»è¾‘
        _, p_norm = stats.shapiro(df[var].dropna()[:5000]) # å…¨é‡æ•°æ®æ­£æ€æ£€éªŒ
        
        if p_norm > 0.05:
            # æ­£æ€åˆ†å¸ƒ: Mean Â± SD
            desc0 = f"{g0.mean():.2f} Â± {g0.std():.2f}"
            desc1 = f"{g1.mean():.2f} Â± {g1.std():.2f}"
            _, p_val = stats.ttest_ind(g0, g1)
            method = "t-test"
        else:
            # éæ­£æ€åˆ†å¸ƒ: Median [IQR]
            desc0 = f"{g0.median():.2f} [{g0.quantile(0.25):.2f}-{g0.quantile(0.75):.2f}]"
            desc1 = f"{g1.median():.2f} [{g1.quantile(0.25):.2f}-{g1.quantile(0.75):.2f}]"
            _, p_val = stats.mannwhitneyu(g0, g1)
            method = "Mann-Whitney U"

        table1_data.append({
            'Variable': var,
            f'Non-POF (N={n_non_pof})': desc0,
            f'POF (N={n_pof})': desc1,
            'P-value': p_val,
            'Test': method
        })

    # --- B. åˆ†ç±»å˜é‡å¤„ç† ---
    # --- B. åˆ†ç±»å˜é‡å¤„ç† (ä¿®å¤ç©ºæ•°æ®æŠ¥é”™) ---
    for var in categorical_vars:
        if var not in df.columns:
            print(f"   âš ï¸ è·³è¿‡åˆ†ç±»å˜é‡ {var}: ä¸åœ¨åˆ—åä¸­")
            continue
            
        # ç»Ÿè®¡æœ‰æ•ˆæ ·æœ¬æ•°ï¼ˆæ’é™¤è¯¥åˆ—çš„ç¼ºå¤±å€¼ï¼‰
        valid_df = df[[var, target]].dropna()
        if len(valid_df) == 0:
            print(f"   âš ï¸ è·³è¿‡åˆ†ç±»å˜é‡ {var}: è¯¥åˆ—æ•°æ®å…¨ä¸ºç©º")
            continue

        # æ ‡ç­¾æ˜ å°„é€»è¾‘
        if var == 'gender':
            valid_df[var+'_label'] = valid_df[var].map({1: 'Male', 0: 'Female'})
        else:
            valid_df[var+'_label'] = valid_df[var].map({1: 'Yes', 0: 'No'})
            
        # ç”Ÿæˆäº¤å‰è¡¨
        contingency = pd.crosstab(valid_df[var+'_label'], valid_df[target])
        
        # å¥å£®æ€§æ£€æŸ¥ï¼šäº¤å‰è¡¨å¿…é¡»æ˜¯ 2x2 æˆ–æ›´å¤§
        if contingency.size == 0 or contingency.shape[0] < 2:
            print(f"   âš ï¸ è·³è¿‡åˆ†ç±»å˜é‡ {var}: æ•°æ®åˆ†å¸ƒä¸è¶³ä»¥è¿›è¡Œå¡æ–¹æ£€éªŒ")
            continue
        
        try:
            _, p_chi2, _, _ = stats.chi2_contingency(contingency)
        except ValueError:
            p_chi2 = np.nan

        first_row = True
        for idx in contingency.index:
            # åŠ¨æ€è·å–å½“å‰å˜é‡ä¸‹çš„ç»„å†…æ ·æœ¬é‡
            c0 = contingency.loc[idx, 0] if 0 in contingency.columns else 0
            c1 = contingency.loc[idx, 1] if 1 in contingency.columns else 0
            
            # ä½¿ç”¨å…¨é‡ N å€¼è®¡ç®—ç™¾åˆ†æ¯”
            desc0 = f"{int(c0)} ({c0/n_non_pof*100:.1f}%)"
            desc1 = f"{int(c1)} ({c1/n_pof*100:.1f}%)"
            
            table1_data.append({
                'Variable': f"{var}: {idx}",
                f'Non-POF (N={n_non_pof})': desc0,
                f'POF (N={n_pof})': desc1,
                'P-value': p_chi2 if first_row else np.nan,
                'Test': "Chi-square"
            })
            first_row = False

    # 3. è¾“å‡ºä¸æ ¼å¼åŒ–
    table1_df = pd.DataFrame(table1_data)
    
    # ä¸¥æ ¼çš„ P å€¼æ ¼å¼åŒ–
    def format_p(x):
        if pd.isna(x): return ""
        if x < 0.001: return "<0.001"
        return f"{x:.3f}"

    table1_df['P-value'] = table1_df['P-value'].apply(format_p)
    
    output_path = os.path.join(SAVE_DIR, "Table1_Full_Raw_Data.csv")
    table1_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    print("-" * 85)
    print(table1_df.to_string(index=False))
    print("-" * 85)
    print(f"âœ… å…¨é‡åŸå§‹æ•°å€¼ Table 1 å·²ç”Ÿæˆ: {output_path}")

if __name__ == "__main__":
    run_module_05_raw_full()
