import os
import joblib
import numpy as np
import pandas as pd
from tableone import TableOne
from sklearn.preprocessing import StandardScaler

# =========================================================
# 1. é…ç½®ä¸è·¯å¾„æ˜ å°„ (åŸºäºæ–°ç›®å½•æ ‘)
# =========================================================
BASE_DIR = "../../"
# è¾“å…¥æ˜¯ 02 æ­¥æ¸…æ´—åçš„ç‰©ç†å€¼æ•°æ®
INPUT_PATH = os.path.join(BASE_DIR, "data/cleaned/mimic_raw_scale.csv")
SAVE_DIR = os.path.join(BASE_DIR, "data/cleaned")
SCALER_PATH = os.path.join(BASE_DIR, "artifacts/scalers/mimic_scaler.joblib")
REPORT_DIR = os.path.join(BASE_DIR, "results/tables")

os.makedirs(SAVE_DIR, exist_ok=True)
os.makedirs(os.path.dirname(SCALER_PATH), exist_ok=True)
os.makedirs(REPORT_DIR, exist_ok=True)

def run_mimic_standardization():
    print("="*70)
    print("ğŸš€ å¯åŠ¨æ¨¡å— 03: äºšç»„åˆ’åˆ†ã€Table 1 å®¡è®¡ä¸ç‰¹å¾æ ‡å‡†åŒ–")
    print("="*70)
    
    if not os.path.exists(INPUT_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {INPUT_PATH}")
        return
    
    df = pd.read_csv(INPUT_PATH)

    # =========================================================
    # 2. äºšç»„åˆ’åˆ† (Subgroup Definition) 
    # =========================================================
    # ä¸´åºŠå®šä¹‰ï¼šå…¥é™¢ 24h å†…è‚Œé… < 1.5 mg/dL ä¸”æ—  CKD å²
    if 'creatinine_max' in df.columns and 'chronic_kidney_disease' in df.columns:
        df['subgroup_no_renal'] = (
            (df['creatinine_max'] < 1.5) & (df['chronic_kidney_disease'] == 0)
        ).astype(int)
        print(f"âœ… äºšç»„æ ‡è®°å®Œæˆ: 'æ— é¢„å­˜è‚¾æŸä¼¤' n = {df['subgroup_no_renal'].sum()}")

    # =========================================================
    # 3. ğŸ“Š è‡ªåŠ¨åŒ–ç»Ÿè®¡åˆ†æ (Table 1 & 2) - åŸºäºç‰©ç†å°ºåº¦
    # =========================================================
    clinical_features = [
        'admission_age', 'bmi', 'heart_failure', 'chronic_kidney_disease', 
        'malignant_tumor', 'bun_min', 'creatinine_max', 'lactate_max', 
        'pao2fio2ratio_min', 'wbc_max', 'alt_max', 'ast_max'
    ]
    outcome_cols = ['pof', 'mortality_28d', 'composite_outcome']
    
    # è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„åˆ—
    cols_for_table = [c for c in (clinical_features + outcome_cols) if c in df.columns]
    categorical = [c for c in ['heart_failure', 'chronic_kidney_disease', 'malignant_tumor', 
                               'mortality_28d', 'composite_outcome', 'subgroup_no_renal'] if c in cols_for_table]
    nonnormal = [c for c in cols_for_table if c not in categorical]

    print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
    t1 = TableOne(df, columns=cols_for_table, categorical=categorical, 
                  nonnormal=nonnormal, groupby='pof', pval=True)
    t1.to_csv(os.path.join(REPORT_DIR, "table1_baseline.csv"))
    print(f"âœ… Table 1 å·²å­˜è‡³: {REPORT_DIR}/table1_baseline.csv")

    if 'subgroup_no_renal' in df.columns:
        print("ğŸ” æ­£åœ¨ç”Ÿæˆ Table 2: è‚¾åŠŸèƒ½äºšç»„å¯¹æ¯”...")
        t2 = TableOne(df, columns=cols_for_table, categorical=categorical, 
                      nonnormal=nonnormal, groupby='subgroup_no_renal', pval=True)
        t2.to_csv(os.path.join(REPORT_DIR, "table2_renal_subgroup.csv"))
        print(f"âœ… Table 2 å·²å­˜è‡³: {REPORT_DIR}/table2_renal_subgroup.csv")

    # =========================================================
    # 4. æ³„éœ²é˜²æŠ¤ï¼šå‰”é™¤æ— å…³ ID ä¸éé¢„æµ‹å˜é‡
    # =========================================================
    # ç»“å±€æ ‡ç­¾å¿…é¡»ä¿ç•™ï¼Œä½†åœ¨æ ‡å‡†åŒ–æ—¶è¦æ’é™¤
    drop_from_modeling = [
        'subject_id', 'hadm_id', 'stay_id', 'database', 
        'admittime', 'dischtime', 'intime', 'deathtime', 'dod',
        'early_death_24_48h', 'hosp_mortality'
    ]
    df_model = df.drop(columns=[c for c in drop_from_modeling if c in df.columns])

    # =========================================================
    # 5. ç‰¹å¾æ ‡å‡†åŒ– (Standardization)
    # =========================================================
    print("\nâš–ï¸ æ‰§è¡Œ Z-score æ ‡å‡†åŒ–...")
    
    # ä»…å¯¹æ•°å€¼å‹è¿ç»­å˜é‡æ ‡å‡†åŒ–ï¼Œæ’é™¤äºŒè¿›åˆ¶æ ‡ç­¾å’Œäºšç»„æ ‡è®°
    binary_cols = outcome_cols + categorical
    numeric_features = [c for c in df_model.select_dtypes(include=[np.number]).columns 
                        if c not in binary_cols]

    scaler = StandardScaler()
    df_model[numeric_features] = scaler.fit_transform(df_model[numeric_features])
    
    # ä¿å­˜ Scaler èµ„äº§ï¼Œç”¨äºåç»­ eICU éªŒè¯é›†å¯¹é½
    joblib.dump(scaler, SCALER_PATH)
    print(f"âœ… Scaler èµ„äº§å·²åºåˆ—åŒ–è‡³: {SCALER_PATH}")

    # =========================================================
    # 6. æŒä¹…åŒ–è¾“å‡º
    # =========================================================
    processed_path = os.path.join(SAVE_DIR, "mimic_processed.csv")
    df_model.to_csv(processed_path, index=False)
    
    print("-" * 70)
    print(f"ğŸ“Š æ¨¡å— 03 å¤„ç†å®Œæˆ:")
    print(f"  - æœ€ç»ˆå¼ é‡ç»´åº¦: {df_model.shape}")
    print(f"  - åŒ…å«æ ‡ç­¾: {outcome_cols}")
    print(f"  - é¢„å¤„ç†æ•°æ®å­˜è‡³: {processed_path}")
    print("-" * 70)

if __name__ == "__main__":
    run_mimic_standardization()
