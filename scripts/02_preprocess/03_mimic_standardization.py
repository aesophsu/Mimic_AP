import os
import joblib
import numpy as np
import pandas as pd
from tableone import TableOne
from sklearn.preprocessing import StandardScaler
from sklearn.experimental import enable_iterative_imputer  # å¿…é¡»å¯¼å…¥ä»¥å¯ç”¨ MICE
from sklearn.impute import IterativeImputer

# =========================================================
# 1. é…ç½®ä¸è·¯å¾„æ˜ å°„ (åŸºäº v3.0 ç›®å½•æ ‘)
# =========================================================
BASE_DIR = "../../"
INPUT_PATH = os.path.join(BASE_DIR, "data/cleaned/mimic_raw_scale.csv")
SAVE_DIR = os.path.join(BASE_DIR, "data/cleaned")

# èµ„äº§æŒä¹…åŒ–è·¯å¾„
ARTIFACT_DIR = os.path.join(BASE_DIR, "artifacts/scalers")
SCALER_PATH = os.path.join(ARTIFACT_DIR, "mimic_scaler.joblib")
IMPUTER_PATH = os.path.join(ARTIFACT_DIR, "mimic_mice_imputer.joblib")
SKEW_CONFIG_PATH = os.path.join(ARTIFACT_DIR, "skewed_cols_config.pkl")

REPORT_DIR = os.path.join(BASE_DIR, "results/tables")

os.makedirs(SAVE_DIR, exist_ok=True)
os.makedirs(ARTIFACT_DIR, exist_ok=True)
os.makedirs(REPORT_DIR, exist_ok=True)

def run_mimic_standardization():
    print("="*70)
    print("ğŸš€ å¯åŠ¨æ¨¡å— 03: äºšç»„åˆ’åˆ†ã€Log è½¬æ¢ã€MICE æ’è¡¥ä¸æ ‡å‡†åŒ–")
    print("="*70)
    
    if not os.path.exists(INPUT_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {INPUT_PATH}")
        return
    
    df = pd.read_csv(INPUT_PATH)

    # =========================================================
    # 2. äºšç»„åˆ’åˆ† (Subgroup Definition) ä¿æŒä¸å˜
    # =========================================================
    if 'creatinine_max' in df.columns and 'chronic_kidney_disease' in df.columns:
        df['subgroup_no_renal'] = (
            (df['creatinine_max'] < 1.5) & (df['chronic_kidney_disease'] == 0)
        ).astype(int)
        print(f"âœ… äºšç»„æ ‡è®°å®Œæˆ: 'æ— é¢„å­˜è‚¾æŸä¼¤' n = {df['subgroup_no_renal'].sum()}")
        
    # LASSO ä¸æ¥å—å­—ç¬¦ä¸²ï¼Œå¿…é¡»åœ¨æ­¤å¤„è½¬æ¢
    if 'gender' in df.columns and df['gender'].dtype == 'object':
        df['gender'] = df['gender'].map({'M': 1, 'F': 0})
        print("âœ… å­—æ®µ 'gender' å·²å®Œæˆæ•°å€¼åŒ–æ˜ å°„ (M->1, F->0)")

    # =========================================================
    # 3. ğŸ“Š è‡ªåŠ¨åŒ–ç»Ÿè®¡åˆ†æ (Table 1 & 2) - åŸºäºç‰©ç†å°ºåº¦
    # =========================================================
    clinical_features = [
        'admission_age', 'bmi', 'heart_failure', 'chronic_kidney_disease', 
        'malignant_tumor', 'bun_min', 'creatinine_max', 'lactate_max', 
        'pao2fio2ratio_min', 'wbc_max', 'alt_max', 'ast_max'
    ]
    outcome_cols = ['pof', 'mortality_28d', 'composite_outcome']
    cols_for_table = [c for c in (clinical_features + outcome_cols) if c in df.columns]
    categorical = [c for c in ['heart_failure', 'chronic_kidney_disease', 'malignant_tumor', 
                               'mortality_28d', 'composite_outcome', 'subgroup_no_renal'] if c in cols_for_table]
    nonnormal = [c for c in cols_for_table if c not in categorical]

    print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š (ç‰©ç†å°ºåº¦)...")
    t1 = TableOne(df, columns=cols_for_table, categorical=categorical, nonnormal=nonnormal, groupby='pof', pval=True)
    t1.to_csv(os.path.join(REPORT_DIR, "table1_baseline.csv"))
    
    if 'subgroup_no_renal' in df.columns:
        t2 = TableOne(df, columns=cols_for_table, categorical=categorical, nonnormal=nonnormal, groupby='subgroup_no_renal', pval=True)
        t2.to_csv(os.path.join(REPORT_DIR, "table2_renal_subgroup.csv"))
    print(f"âœ… Table 1 & 2 å·²å­˜è‡³: {REPORT_DIR}")

    # =========================================================
    # 4. æ³„éœ²é˜²æŠ¤ä¸ç‰¹å¾å‡†å¤‡ (ä¿®æ­£ç‰ˆ)
    # =========================================================
    # A. å®šä¹‰ä¸å‚ä¸å»ºæ¨¡çš„ ID ä¸æ—¶é—´åˆ—
    drop_from_modeling = [
        'subject_id', 'hadm_id', 'stay_id', 'database', 
        'admittime', 'dischtime', 'intime', 'deathtime', 'dod',
        'early_death_24_48h', 'hosp_mortality'
    ]
    
    # B. å®šä¹‰å¿…é¡»ä¿æŒåŸå§‹æ ¼å¼çš„åˆ— (æ ‡ç­¾ã€å­ç»“å±€ã€äºšç»„æ ‡è®°)
    protected_cols = [
        'pof', 'resp_pof', 'cv_pof', 'renal_pof', 
        'mortality_28d', 'composite_outcome', 'subgroup_no_renal',
        'gender', 'heart_failure', 'chronic_kidney_disease', 
        'malignant_tumor', 'mechanical_vent_flag', 'vaso_flag'
    ]
    
    df_model = df.drop(columns=[c for c in drop_from_modeling if c in df.columns])

    # å¼ºåˆ¶å°†ä¿æŠ¤åˆ—è½¬æ¢ä¸ºæ•´æ•° (é˜²æ­¢æ ‡å‡†åŒ–æ±¡æŸ“)
    for col in protected_cols:
        if col in df_model.columns:
            df_model[col] = df_model[col].fillna(0).astype(int)

    # å¼ºåˆ¶å‰”é™¤éæ•°å€¼åˆ— (å¦‚ Race ç­‰æ–‡æœ¬)
    remaining_text = df_model.select_dtypes(include=['object']).columns.tolist()
    if remaining_text:
        print(f"âš ï¸ è­¦å‘Š: å¼ºåˆ¶å‰”é™¤éæ•°å€¼åˆ—ä»¥é˜²æŠ¥é”™: {remaining_text}")
        df_model = df_model.drop(columns=remaining_text)
        
    # C. ç¡®å®šçœŸæ­£éœ€è¦â€œæ•°å€¼å¤„ç†â€çš„ç‰¹å¾ (æ’é™¤ä¿æŠ¤åˆ—)
    numeric_features = [c for c in df_model.select_dtypes(include=[np.number]).columns 
                        if c not in protected_cols]
    
    print(f"âœ… ç‰¹å¾åˆ†ç±»å®Œæˆ: æ•°å€¼ç‰¹å¾ {len(numeric_features)} ä¸ª, ä¿æŠ¤åˆ— {len(protected_cols)} ä¸ª")

    # =========================================================
    # 5. ğŸ§ª æ ¸å¿ƒå¢å¼ºï¼šåŠ¨æ€ Log1p è½¬æ¢ (å¤„ç†åæ€)
    # =========================================================
    skewed_cols = ['creatinine_max', 'creatinine_min', 'bun_max', 'bun_min',
                   'wbc_max', 'wbc_min', 'glucose_max', 'glucose_min',
                   'lactate_max', 'alt_max', 'ast_max', 'bilirubin_total_max']
    existing_skewed = [c for c in skewed_cols if c in numeric_features]
    
    print(f"ğŸ”„ æ‰§è¡Œ Log1p è½¬æ¢ (å¤„ç† {len(existing_skewed)} ä¸ªåæ€æŒ‡æ ‡)...")
    for col in existing_skewed:
        df_model[col] = np.log1p(df_model[col].clip(lower=0))
    
    joblib.dump(existing_skewed, SKEW_CONFIG_PATH)

    # =========================================================
    # 6. ğŸ§ª æ ¸å¿ƒå¢å¼ºï¼šMICE å¤šé‡æ’è¡¥ (ä»…é’ˆå¯¹æ•°å€¼ç‰¹å¾)
    # =========================================================
    print("ğŸ§ª å¯åŠ¨ MICE å¤šé‡æ’è¡¥ (ä»…å¤„ç† numeric_features)...")
    imputer = IterativeImputer(max_iter=10, random_state=42, initial_strategy='median')
    
    # æ³¨æ„ï¼šåªå¯¹æ•°å€¼åˆ—è¿›è¡Œ fit å’Œ transform
    df_model[numeric_features] = imputer.fit_transform(df_model[numeric_features])
    joblib.dump(imputer, IMPUTER_PATH)

    # =========================================================
    # 7. âš–ï¸ Z-score æ ‡å‡†åŒ– (ä»…é’ˆå¯¹æ•°å€¼ç‰¹å¾)
    # =========================================================
    print("âš–ï¸ æ‰§è¡Œ Z-score æ ‡å‡†åŒ– (æ’é™¤æ ‡ç­¾å’Œäºšç»„åˆ—)...")
    scaler = StandardScaler()
    
    # å…³é”®ç‚¹ï¼šåªæ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾ï¼Œprotected_cols ä¿æŒåŸæ ·
    df_model[numeric_features] = scaler.fit_transform(df_model[numeric_features])
    joblib.dump(scaler, SCALER_PATH)

    # =========================================================
    # 8. æ£€æŸ¥å¹¶ä¿å­˜
    # =========================================================
    if 'subgroup_no_renal' in df_model.columns:
        unique_vals = df_model['subgroup_no_renal'].unique()
        print(f"ğŸš© æœ€ç»ˆäºšç»„åˆ—çŠ¶æ€æ£€æŸ¥: {unique_vals} (åº”ä¸º [1 0] æˆ– [0 1])")
    
    print(f"\nğŸ“‹ åŸå§‹æ•°æ®æ¢æµ‹: {df.shape[0]} è¡Œ, {df.shape[1]} åˆ—")
    print(f"{'Feature Name':<25} | {'Missing%':<10} | {'Median':<10} | {'Mean':<10} | {'Max':<10}")
    print("-" * 75)
        
    processed_path = os.path.join(SAVE_DIR, "mimic_processed.csv")
    df_model.to_csv(processed_path, index=False)   
    
    print("-" * 70)
    print(f"âœ… æ¨¡å— 03 å¤„ç†å®Œæˆï¼")
    print(f"   - å»ºæ¨¡å¼ é‡: {processed_path}")
    print(f"   - æ ‡å‡†åŒ–åçš„ç‰¹å¾æ•°: {len(numeric_features)}")
    print("-" * 70)

if __name__ == "__main__":
    run_mimic_standardization()
