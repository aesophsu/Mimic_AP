import os
import json
import numpy as np
import pandas as pd

# =========================================================
# 1. é…ç½®ä¸è·¯å¾„æ˜ å°„ (åŸºäºæ–°ç›®å½•æ ‘)
# =========================================================
BASE_DIR = "../../"
INPUT_PATH = os.path.join(BASE_DIR, "data/raw/mimic_raw_data.csv")
DICT_PATH = os.path.join(BASE_DIR, "artifacts/features/feature_dictionary.json")
SAVE_DIR = os.path.join(BASE_DIR, "data/cleaned")
MISSING_THRESHOLD = 0.3

if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR)

class FeatureAuditor:
    """ä¸´åºŠç‰¹å¾å®¡è®¡å™¨ï¼šè´Ÿè´£æ ¹æ®å­—å…¸å®šä¹‰æ ¡éªŒå•ä½ä¸ç”Ÿç†èŒƒå›´"""
    
    def __init__(self, dict_path):
        with open(dict_path, 'r', encoding='utf-8') as f:
            self.feature_dict = json.load(f)

    def audit_units_and_ranges(self, df):
        df_cleaned = df.copy()
        print(f"\n{'Feature':<20} | {'Action':<40} | {'Status'}")
        print("-" * 80)

        for col, config in self.feature_dict.items():
            # å¢åŠ ä¸¤ä¸ªå‰ç½®æ£€æŸ¥ï¼š
            # 1. åˆ—å¿…é¡»åœ¨ DataFrame ä¸­
            # 2. åˆ—å¿…é¡»æ˜¯æ•°å€¼ç±»å‹ (é¿å…å¤„ç†æ—¥æœŸæˆ– ID å­—ç¬¦ä¸²)
            if col not in df_cleaned.columns:
                continue
            
            if not pd.api.types.is_numeric_dtype(df_cleaned[col]):
                # å¦‚æœå­—å…¸é‡Œå®šä¹‰äº†ä½†æ•°æ®é‡Œæ˜¯å­—ç¬¦ä¸²/æ—¥æœŸï¼Œè·³è¿‡å®¡è®¡
                continue

            med = df_cleaned[col].median()
            log_min = config['ref_range']['logical_min']
            log_max = config['ref_range']['logical_max']
            factor = config.get('conversion_factor', 1.0)

            if config.get("apply_expm1", False) and pd.notnull(med):
                if med < 10:  # åªæœ‰å½“é‡çº§æ˜æ˜¾æ˜¯ Log æ—¶æ‰è§¦å‘
                    df_cleaned[col] = np.expm1(df_cleaned[col])
                    print(f"{col:<20} | Applied expm1 restoration (Anti-Log) | ğŸ”„")
                    # æ›´æ–° med ä»¥ä¾¿åç»­çš„å•ä½è½¬æ¢é€»è¾‘ä½¿ç”¨æ­£ç¡®çš„ä¸­å€¼
                    med = df_cleaned[col].median()

            # --- åŸæœ‰çš„ï¼šå•ä½è‡ªåŠ¨å¯¹é½ ---
            if pd.notnull(med) and log_min is not None:
                if med < (log_min * 0.2) and factor != 1.0:
                    df_cleaned[col] = df_cleaned[col] * factor
                    print(f"{col:<20} | Applied conversion factor x{factor:<10} | âœ…")
            
            # --- åŸæœ‰çš„ï¼šç”Ÿç†å¼‚å¸¸å€¼æ¸…æ´— ---
            if log_min is not None and log_max is not None:
                mask = (df_cleaned[col] < log_min) | (df_cleaned[col] > log_max)
                if mask.any():
                    df_cleaned.loc[mask, col] = np.nan
                    print(f"{col:<20} | Removed {mask.sum():>3} physiologic outliers | âš ï¸")

        return df_cleaned

# =========================================================
# 2. æ ¸å¿ƒæ¸…æ´—æ¨¡å—
# =========================================================
def run_cross_database_alignment():
    print("="*70)
    print("ğŸš€ å¯åŠ¨æ¨¡å— 02: ä¸´åºŠç‰¹å¾ç©ºé—´å®¡è®¡ä¸æ¸…æ´— (MIMIC-IV)")
    print("="*70)

    if not os.path.exists(INPUT_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {INPUT_PATH}")
        return

    df = pd.read_csv(INPUT_PATH)
    auditor = FeatureAuditor(DICT_PATH)
    
    # 2.1 ç»“å±€æŒ‡æ ‡è§„æ•´ä¸æ—©äº¡ä¿®æ­£
    if 'early_death_24_48h' in df.columns:
        early_death_mask = (df['early_death_24_48h'] == 1)
        df.loc[early_death_mask, 'pof'] = 1
        if 'mortality_28d' in df.columns:
            df.loc[early_death_mask, 'mortality_28d'] = 1

    if 'pof' in df.columns and 'mortality_28d' in df.columns:
        df['composite_outcome'] = ((df['pof'] == 1) | (df['mortality_28d'] == 1)).astype(int)
        print("âœ… [Labels] ç»“å±€æŒ‡æ ‡å¯¹é½å®Œæˆã€‚")

    # 2.2 æ ¸å¿ƒä¿æŠ¤ç™½åå•ä¸ç¼ºå¤±ç‡è¿‡æ»¤
    white_list = [
        'subject_id', 'hadm_id', 'stay_id', 'database',
        'pof', 'mortality_28d', 'composite_outcome', 'early_death_24_48h',
        'lactate_max', 'pao2fio2ratio_min', 'lipase_max', 'creatinine_max', 'bun_min'
    ]
    
    missing_pct = df.isnull().mean()
    cols_to_drop = [c for c in missing_pct[missing_pct > MISSING_THRESHOLD].index if c not in white_list]
    df = df.drop(columns=cols_to_drop)
    print(f"ğŸ—‘ï¸ [Filter] å·²å‰”é™¤ç¼ºå¤±ç‡ >{MISSING_THRESHOLD*100}% çš„éæ ¸å¿ƒç‰¹å¾ã€‚")

    # 2.3 ç‰©ç†å•ä½å®¡è®¡ä¸ç”Ÿç†èŒƒå›´çº¦æŸ
    df = auditor.audit_units_and_ranges(df)

    # 2.4 ç»Ÿè®¡æˆªæ–­ (Statistical Clipping)
    print("\nâœ‚ï¸ [Clipping] æ‰§è¡Œ 1%-99% ç»Ÿè®¡ç›–å¸½å¤„ç†...")
    binary_cols = ['gender_num', 'vaso_flag', 'mechanical_vent_flag', 'composite_outcome', 'pof']
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    for col in numeric_cols:
        if col not in white_list and col not in binary_cols:
            lower = df[col].quantile(0.01)
            upper = df[col].quantile(0.99)
            df[col] = df[col].clip(lower, upper)

    # 2.5 å®¡è®¡æ€»ç»“ä¸æŒä¹…åŒ–
    print("\n" + "-"*70)
    print(f"ğŸ“Š æ¨¡å—æ¸…æ´—ç»Ÿè®¡: æ ·æœ¬ {df.shape[0]} | ç‰¹å¾ {df.shape[1]}")
    
    # æŠ½å–æ ¸å¿ƒæŒ‡æ ‡è¿›è¡Œå®¡è®¡æŠ¥å‘Š
    report_cols = ['bun_min', 'creatinine_max', 'lactate_max', 'pao2fio2ratio_min']
    print("\nğŸ” å…³é”®ç‰¹å¾ç»Ÿè®¡å®¡è®¡:")
    for c in report_cols:
        if c in df.columns:
            print(f"  > {c:<20}: Median={df[c].median():>8.2f} | Missing={df[c].isnull().mean()*100:>6.2f}%")

    save_path = os.path.join(SAVE_DIR, "mimic_raw_scale.csv")
    df.to_csv(save_path, index=False)
    print(f"\nâœ… å·²ç”Ÿæˆä¸­é—´äº§ç‰©: {save_path}")

if __name__ == "__main__":
    run_cross_database_alignment()
