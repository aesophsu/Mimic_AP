import os
import json
import joblib
import numpy as np
import pandas as pd

# =========================================================
# 1. é…ç½®ä¸è·¯å¾„ (éµå¾ª 14 æ­¥æ ‡å‡†ç›®å½•æ ‘)
# =========================================================
BASE_DIR = "../../"
RAW_EICU_PATH = os.path.join(BASE_DIR, "data/raw/eicu_raw_data.csv")  # 08æ­¥ SQL äº§ç‰©
EXTERNAL_DIR = os.path.join(BASE_DIR, "data/external")
MODEL_ROOT = os.path.join(BASE_DIR, "artifacts/models")
SCALER_ROOT = os.path.join(BASE_DIR, "artifacts/scalers")

OUTCOMES = ['pof', 'mortality_28d', 'composite_outcome']

for path in [EXTERNAL_DIR]:
    if not os.path.exists(path):
        os.makedirs(path)

# =========================================================
# 2. æ ¸å¿ƒæ¸…æ´—é€»è¾‘ (ç‰©ç†å¯¹é½)
# =========================================================
def physical_alignment(df_raw):
    """
    å®ç°åŠŸèƒ½ 1: ç‰©ç†å°ºåº¦å¯¹é½
    å¤„ç†æ€§åˆ«ã€æç«¯å¼‚å¸¸å€¼ã€å•ä½ç»Ÿä¸€ï¼Œä¿ç•™ç‰©ç†åŸå€¼ã€‚
    """
    df = df_raw.copy()
    print(f"ğŸ› ï¸ [1/4] æ‰§è¡Œç‰©ç†å¯¹é½ (Physical Alignment)...")

    # 1.1 æ€§åˆ«ç»Ÿä¸€ç¼–ç  (M/1, F/0)
    if 'gender' in df.columns:
        df['gender'] = df['gender'].map({'M': 1, 'F': 0, 'Male': 1, 'Female': 0, 1: 1, 0: 0}).fillna(1)
    
    # 1.2 å¤„ç† PF Ratio (ç”Ÿç†ä¸Šé™é”å®š)
    if 'pao2fio2ratio_min' in df.columns:
        df['pao2fio2ratio_min'] = df['pao2fio2ratio_min'].clip(lower=20, upper=800).fillna(400)

    # 1.3 å¤„ç† pH æç«¯å¼‚å¸¸ (æ ¹æ® SQL å·²æœ‰çš„ 6.7-7.8 è¿›ä¸€æ­¥ç¡®è®¤)
    ph_cols = [c for c in df.columns if 'ph' in c.lower()]
    for col in ph_cols:
        df[col] = df[col].clip(lower=6.7, upper=7.8)

    # ä¿å­˜ç‰©ç†åŸå€¼ç‰ˆ (ç”¨äº Step 10: Table 1)
    save_path = os.path.join(EXTERNAL_DIR, "eicu_aligned.csv")
    df.to_csv(save_path, index=False)
    print(f"  âœ… ç‰©ç†åŸå€¼èµ„äº§å·²ä¿å­˜: {save_path}")
    return df

# =========================================================
# 3. ç»“å±€ä¸“å±å¤„ç† (Log1p & Standardization)
# =========================================================
def process_outcome_alignment(df_aligned):
    """
    å®ç°åŠŸèƒ½ 2 & 3: ç‰¹å¾å·¥ç¨‹æŠ•å½±ä¸æ ‡å‡†åŒ–æ˜ å°„
    """
    # åŠ è½½å…¨å±€å¯¹æ•°é…ç½® (03æ­¥äº§å‡º)
    skewed_config_path = os.path.join(SCALER_ROOT, "skewed_cols_config.pkl")
    skewed_cols = joblib.load(skewed_config_path) if os.path.exists(skewed_config_path) else []

    for target in OUTCOMES:
        print(f"\nğŸš€ æ­£åœ¨å¤„ç†ç»“å±€æ˜ å°„: [{target.upper()}]")
        
        # 3.1 åŠ è½½ 06 æ­¥ä¿å­˜çš„èµ„äº§ Bundle
        bundle_path = os.path.join(SCALER_ROOT, f"train_assets_bundle_{target}.pkl")
        scaler_path = os.path.join(MODEL_ROOT, target, "scaler.pkl")
        
        if not (os.path.exists(bundle_path) and os.path.exists(scaler_path)):
            print(f"  âš ï¸ è·³è¿‡ {target}: æ‰¾ä¸åˆ° Bundle æˆ– Scaler èµ„äº§ã€‚")
            continue

        bundle = joblib.load(bundle_path)
        scaler = joblib.load(scaler_path)
        selected_features = bundle['feature_order']  # è®­ç»ƒæ—¶çš„ç‰¹å¾é¡ºåº
        
        # 3.2 å¤åˆ¶å‰¯æœ¬è¿›è¡Œå»ºæ¨¡é¢„å¤„ç†
        df_target = df_aligned.copy()

        # 3.3 Log1p Alignment (å¯¹æ•°è¡¥ä¸)
        print(f"ğŸª„ [2/4] æ‰§è¡Œå¯¹æ•°è¡¥ä¸å¯¹é½...")
        for col in skewed_cols:
            if col in df_target.columns and col in selected_features and col != 'ph_min':
                # ä¸´åºŠå¯å‘å¼æ ¡éªŒï¼šåªæœ‰ä¸­å€¼è¾ƒå¤§æ—¶æ‰æ‰§è¡Œ Logï¼ˆåŒæ­¥ 02/03 æ­¥é€»è¾‘ï¼‰
                if df_target[col].median() > 3:
                    df_target[col] = np.log1p(df_target[col].astype(float).clip(lower=0))

        # 3.4 ç®€åŒ–ç‰¹å¾çŸ©é˜µæ„å»º (ä¸å†å¯»æ‰¾ templated)
        print(f"ğŸ› ï¸ [3/4] æ„å»ºé€‰å®šçš„ {len(selected_features)} ä¸ªç‰¹å¾çŸ©é˜µ...")
        X_eicu_final = pd.DataFrame(index=df_target.index)
        for feat in selected_features:
            if feat in df_target.columns:
                # ç¼ºå¤±å€¼å¤„ç†ï¼šä½¿ç”¨ eICU å±€éƒ¨ä¸­ä½æ•°å¡«å……
                local_med = df_target[feat].median()
                X_eicu_final[feat] = df_target[feat].fillna(local_med if not pd.isna(local_med) else 0)
            else:
                print(f"  âš ï¸ è­¦å‘Š: eICU ç¼ºå°‘ç‰¹å¾ [{feat}]ï¼Œå¡«å…… 0")
                X_eicu_final[feat] = 0
        
        # ä¸¥æ ¼å¯¹é½ç‰¹å¾åˆ—é¡ºåº
        X_eicu_final = X_eicu_final[selected_features]

        # 3.5 æ ‡å‡†åŒ–æ˜ å°„ (Standard Scaling)
        print(f"âš–ï¸ [4/4] åº”ç”¨æ ‡å‡†åŒ–æŠ•å½± (Scaler Transformation)...")
        X_eicu_std_all = scaler.transform(X_eicu_final)
        X_eicu_final_features = pd.DataFrame(X_eicu_std_all, columns=selected_features, index=df_target.index)

        # 3.6 åˆå¹¶æ ‡ç­¾å¹¶ä¿å­˜
        target_csv_path = os.path.join(EXTERNAL_DIR, f"eicu_processed_{target}.csv")
        if target in df_target.columns:
            df_final_to_save = pd.concat([X_eicu_final_features, df_target[target].reset_index(drop=True)], axis=1)
            df_final_to_save.to_csv(target_csv_path, index=False)
            print(f"âœ… å¤„ç†æˆåŠŸï¼å»ºæ¨¡å¼ é‡å·²ä¿å­˜: {target_csv_path} (Shape: {df_final_to_save.shape})")

# =========================================================
# 4. ä¸»ç¨‹åºå…¥å£
# =========================================================
def main():
    if not os.path.exists(RAW_EICU_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° eICU åŸå§‹æ•°æ® {RAW_EICU_PATH}ï¼Œè¯·ç¡®è®¤ 08 æ­¥ SQL å·²è¿è¡Œå¹¶å¯¼å‡ºã€‚")
        return

    print("ğŸ“– æ­£åœ¨åŠ è½½ eICU åŸå§‹å¯¼å‡ºæ•°æ®...")
    df_raw = pd.read_csv(RAW_EICU_PATH)
    
    # ç¬¬ä¸€æ­¥ï¼šç‰©ç†å¯¹é½ä¸ Table 1 åŸå§‹æ•°æ®å‡†å¤‡
    df_aligned = physical_alignment(df_raw)
    
    # ç¬¬äºŒæ­¥ï¼šé’ˆå¯¹å„ç»“å±€è¿›è¡Œ Log å’Œ Scale æŠ•å½±
    process_outcome_alignment(df_aligned)
    
    print("\nâœ¨ 09 æ­¥ä»»åŠ¡åœ†æ»¡å®Œæˆï¼eICU éªŒè¯é›†å·²å®Œå…¨å°±ç»ªã€‚")

if __name__ == "__main__":
    main()
