import os
import json
import joblib
import numpy as np
import pandas as pd

# ===================== è·¯å¾„é…ç½® =====================
BASE_DIR = "../../"
EICU_RAW_PATH = os.path.join(BASE_DIR, "data/raw/eicu_raw_data.csv")
DICT_PATH = os.path.join(BASE_DIR, "artifacts/features/feature_dictionary.json")
ARTIFACT_DIR = os.path.join(BASE_DIR, "artifacts/scalers")
SAVE_DIR = os.path.join(BASE_DIR, "data/external") 
SELECTED_FEAT_PATH = os.path.join(BASE_DIR, "features/selected_features.json")

os.makedirs(SAVE_DIR, exist_ok=True)

class EICUAuditor:
    def __init__(self, dict_path):
        with open(dict_path, 'r', encoding='utf-8') as f:
            self.feature_dict = json.load(f)

    def apply_clinical_rules(self, df):
        """æ‰§è¡Œä¸´åºŠå®¡è®¡ï¼šå•ä½è‡ªåŠ¨ä¿®å¤ + ç”Ÿç†ç¡¬è¿‡æ»¤ + ç»“å±€å¯¹é½ + äºšç»„æ ‡è®°"""
        df_cleaned = df.copy()
        print(f"\nğŸ“‹ å¯åŠ¨ä¸´åºŠç©ºé—´å®¡è®¡: {df.shape[0]} è¡Œ")
        
        # 0. ç»“å±€å˜é‡é‡å‘½åå¯¹é½
        rename_map = {'mortality_28d': 'mortality', 'composite_outcome': 'composite'}
        df_cleaned = df_cleaned.rename(columns={k: v for k, v in rename_map.items() if k in df_cleaned.columns})

        # --- æ–°å¢ï¼šäºšç»„æ ‡è®° (subgroup_no_renal) ---
        if 'creatinine_max' in df_cleaned.columns:
            df_cleaned['subgroup_no_renal'] = (df_cleaned['creatinine_max'] < 1.5).astype(int)
            print("âœ… å·²è®¡ç®—äºšç»„æ ‡è®°: subgroup_no_renal (Cr < 1.5)")

        print(f"{'Feature':<20} | {'Action':<40} | {'Status'}")
        print("-" * 80)

        for col, config in self.feature_dict.items():
            if col not in df_cleaned.columns or not pd.api.types.is_numeric_dtype(df_cleaned[col]):
                continue
            
            ref = config.get('ref_range', {})
            log_min = ref.get('logical_min')
            log_max = ref.get('logical_max')
            factor = config.get('conversion_factor', 1.0)
            
            series_curr = df_cleaned[col].dropna()
            if series_curr.empty: continue
            
            med = series_curr.median()
            
            # 1. å•ä½è½¬æ¢æ¢æµ‹
            if log_min is not None and factor != 1.0:
                if med < (log_min * 0.2): 
                    df_cleaned[col] = df_cleaned[col] * factor
                    print(f"{col:<20} | Applied unit factor x{factor:<11} | âœ…")
            
            # 2. ç”Ÿç†èŒƒå›´ç¡¬è¿‡æ»¤
            if log_min is not None and log_max is not None:
                mask = (df_cleaned[col] < log_min) | (df_cleaned[col] > log_max)
                if mask.any():
                    df_cleaned.loc[mask, col] = np.nan
                    print(f"{col:<20} | Cleared {mask.sum():>3} physiologic outliers | âš ï¸")
        
        return df_cleaned

def generate_eicu_processed(target, df_audited, assets):
    """åŸºäºå®¡è®¡åçš„æ•°æ®ï¼Œä¸ºç‰¹å®šç»“å±€ç”Ÿæˆæ¨¡å‹è¾“å…¥æ–‡ä»¶"""
    print(f"\nğŸ› ï¸ æ­£åœ¨å¯¹é½ç›®æ ‡ç»“å±€: {target}")

    # 1. åŠ è½½ç‰¹å¾é€‰æ‹©æ¸…å•
    try:
        with open(SELECTED_FEAT_PATH, 'r', encoding='utf-8') as f:
            selected_all = json.load(f)
        selected_features = selected_all[target]['features']
    except Exception as e:
        print(f"âŒ åŠ è½½ç‰¹å¾æ¸…å•å¤±è´¥: {e}")
        return
    
    # 2. å¼ºåˆ¶ç‰¹å¾é¡ºåºå¯¹é½
    imputer = assets['imputer']
    scaler = assets['scaler']
    required_features = imputer.feature_names_in_
    
    df_aligned = pd.DataFrame(index=df_audited.index)
    for col in required_features:
        if col in df_audited.columns:
            df_aligned[col] = df_audited[col]
        else:
            df_aligned[col] = np.nan
            print(f"âš ï¸ ç¼ºå¤±ç‰¹å¾: {col}, å°†åœ¨æ’è¡¥é˜¶æ®µå¡«å……")

    # 3. åº”ç”¨ Log å˜æ¢
    for col in assets['skewed_cols']:
        if col in df_aligned.columns:
            df_aligned[col] = np.log1p(df_aligned[col].clip(lower=0))

    # 4. å¤ç”¨èµ„äº§ï¼šæ’è¡¥ä¸æ ‡å‡†åŒ–
    print(f"   åº”ç”¨ MIMIC èµ„äº§è¿›è¡Œ Transform...")
    df_imputed_raw = imputer.transform(df_aligned)
    df_scaled_raw = scaler.transform(df_imputed_raw)
    
    df_scaled = pd.DataFrame(df_scaled_raw, columns=required_features, index=df_audited.index)

    # --- æ–°å¢ï¼šæ ‡å‡†åŒ–åå‡å€¼æ£€æŸ¥ ---
    max_mean_abs = df_scaled.mean().abs().max()
    print(f"   ğŸ“Š æ ‡å‡†åŒ–åå‡å€¼æ£€æŸ¥: {max_mean_abs:.4f} (åº”æ¥è¿‘ 0)")

    # 5. æ¢å¤ä¿æŠ¤åˆ—
    protected_cols = ['pof', 'mortality', 'composite', 'gender', 'malignant_tumor', 
                      'mechanical_vent_flag', 'vaso_flag', 'dialysis_flag', 'subgroup_no_renal']
    for col in protected_cols:
        if col in df_audited.columns:
            df_scaled[col] = df_audited[col].fillna(0).astype(int)

    # --- æ–°å¢ï¼šeICU å¯¹é½åå…³é”®ç‰¹å¾åˆ†å¸ƒå®¡è®¡ ---
    print(f"\nğŸ“ˆ eICU å¯¹é½ååˆ†å¸ƒå®¡è®¡ï¼ˆ{target}ï¼‰ï¼š")
    key_cols = ['creatinine_max', 'lactate_max', 'pao2fio2ratio_min', 'ph_min']
    for col in key_cols:
        if col in df_scaled.columns:
            series = df_scaled[col].dropna()
            print(f"  {col:<20}: Mean={series.mean():.4f} | Std={series.std():.4f}")

    # 6. ä¿å­˜æœ€ç»ˆæ¨ç†é›†
    save_path = os.path.join(SAVE_DIR, f"eicu_processed_{target}.csv")
    df_scaled.to_csv(save_path, index=False)
    print(f"âœ… å®Œæˆ: {save_path}")

def main():
    print("="*70)
    print("ğŸš€ æ¨¡å— 09: eICU æ•°æ®æ¸…æ´—ä¸å¤šç»“å±€å¯¹é½")
    print("="*70)

    # 1. ã€æ–°å¢ã€‘èµ„äº§åŠ è½½çš„é”™è¯¯å¤„ç†
    try:
        assets = {
            'scaler': joblib.load(os.path.join(ARTIFACT_DIR, "mimic_scaler.joblib")),
            'imputer': joblib.load(os.path.join(ARTIFACT_DIR, "mimic_mice_imputer.joblib")),
            'skewed_cols': joblib.load(os.path.join(ARTIFACT_DIR, "skewed_cols_config.pkl")),
            'bundle': joblib.load(os.path.join(ARTIFACT_DIR, "train_assets_bundle.pkl"))
        }
        print("âœ… MIMIC èµ„äº§åŠ è½½æˆåŠŸã€‚")
    except Exception as e:
        print(f"âŒ åŠ è½½ MIMIC èµ„äº§å¤±è´¥: {e}")
        return

    # 2. åˆå§‹æ•°æ®è¯»å–
    if not os.path.exists(EICU_RAW_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° eICU åŸå§‹æ•°æ® {EICU_RAW_PATH}")
        return
        
    df_raw = pd.read_csv(EICU_RAW_PATH)
    auditor = EICUAuditor(DICT_PATH)

    # 3. ç”Ÿæˆ eicu_raw_scale.csv
    df_audited = auditor.apply_clinical_rules(df_raw)
    
    print("\nâœ‚ï¸ æ‰§è¡Œ 1%-99% ç»Ÿè®¡ç›–å¸½...")
    numeric_cols = df_audited.select_dtypes(include=[np.number]).columns
    exclude_clipping = ['pof', 'mortality', 'composite', 'gender', 'malignant_tumor', 'subgroup_no_renal']
    for col in numeric_cols:
        if col not in exclude_clipping:
            lower, upper = df_audited[col].quantile(0.01), df_audited[col].quantile(0.99)
            if pd.notnull(lower) and pd.notnull(upper):
                df_audited[col] = df_audited[col].clip(lower, upper)

    scale_save_path = os.path.join(SAVE_DIR, "eicu_raw_scale.csv")
    df_audited.to_csv(scale_save_path, index=False)
    print(f"\nâ­ ä¸´åºŠå®¡è®¡ç‰ˆå·²ç”Ÿæˆ (ç”¨äº Table 1/æ¼‚ç§»åˆ†æ): {scale_save_path}")

    # 4. ç”Ÿæˆ Z-score å˜æ¢æ¨ç†ç‰ˆ
    for target in ['pof', 'mortality', 'composite']:
        generate_eicu_processed(target, df_audited, assets)

    print("\n" + "="*70)
    print("âœ… æ¨¡å— 09 è¿è¡ŒæˆåŠŸï¼å·²å‡†å¤‡å¥½ç»Ÿè®¡ä¸é¢„æµ‹ä¸¤å¥—æ•°æ®ã€‚")

if __name__ == "__main__":
    main()
