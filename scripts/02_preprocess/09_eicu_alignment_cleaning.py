import os
import json
import joblib
import numpy as np
import pandas as pd

# ===================== è·¯å¾„é…ç½® (Paths) =====================
BASE_DIR = "../../"
EICU_RAW_PATH = os.path.join(BASE_DIR, "data/raw/eicu_raw_data.csv")
DICT_PATH = os.path.join(BASE_DIR, "artifacts/features/feature_dictionary.json")
SELECTED_FEAT_PATH = os.path.join(BASE_DIR, "artifacts/features/selected_features.json")
ARTIFACT_DIR = os.path.join(BASE_DIR, "artifacts/scalers")
SAVE_DIR = os.path.join(BASE_DIR, "data/external")

# ===================== å…¨å±€å¸¸é‡ (Constants) =====================
# ä¿æŠ¤åˆ—ï¼šä¸å‚ä¸ Z-score å˜æ¢ï¼Œéœ€åœ¨æœ€åæ¢å¤çš„åŸæ ·åˆ—
PROTECTED_COLS = [
    'pof', 'mortality', 'composite', 'gender', 'malignant_tumor', 
    'mechanical_vent_flag', 'vaso_flag', 'dialysis_flag', 'subgroup_no_renal'
]

# æ ¸å¿ƒä¿ç•™åˆ—ï¼šå®¡è®¡é˜¶æ®µå¿…é¡»ä¿ç•™çš„åˆ—ï¼ˆåŒ…å« ID å’Œç»“å±€å˜é‡ï¼‰
ESSENTIAL_COLS = ['patientunitstayid', 'uniquepid', 'los'] + PROTECTED_COLS

# ç›–å¸½æ’é™¤åˆ—ï¼šç»Ÿè®¡ç›–å¸½ (Winsorization) æ—¶ä¸éœ€è¦å¤„ç†çš„åˆ—
EXCLUDE_CLIPPING = ['patientunitstayid', 'uniquepid', 'los'] + PROTECTED_COLS

os.makedirs(SAVE_DIR, exist_ok=True)

def audit_clinical_limits(df, feature_dict):
    """ç”Ÿç†è§„åˆ™å®¡è®¡ï¼šæ‰§è¡Œå•ä½æ¢ç®—ä¸ç‰©ç†æé™å‰”é™¤"""
    df_temp = df.copy()
    for col, config in feature_dict.items():
        if col not in df_temp.columns or not pd.api.types.is_numeric_dtype(df_temp[col]):
            continue
        
        ref = config.get('ref_range', {})
        log_min, log_max = ref.get('logical_min'), ref.get('logical_max')
        factor = config.get('conversion_factor', 1.0)
        
        series_valid = df_temp[col].dropna()
        if series_valid.empty: continue
        
        # 1. è‡ªåŠ¨å•ä½ä¿®å¤ï¼šæ£€æµ‹åˆ°ä¸­å€¼è¿œä½äºé€»è¾‘ä¸‹é™æ—¶åº”ç”¨è½¬æ¢ç³»æ•°
        if log_min is not None and factor != 1.0:
            if series_valid.median() < (log_min * 0.2): 
                df_temp[col] *= factor
        
        # 2. æé™å€¼æ¸…ç†ï¼šè¶…å‡ºåŒ»å­¦é€»è¾‘èŒƒå›´çš„æ•°æ®ç½®ä¸º NaN
        if log_min is not None and log_max is not None:
            mask = (df_temp[col] < log_min) | (df_temp[col] > log_max)
            df_temp.loc[mask, col] = np.nan
            
    return df_temp

def apply_clinical_audit_workflow(df, auditor_config):
    """ä¸»å®¡è®¡æµï¼šæ‰§è¡Œåˆ—åå¯¹é½ã€ç‰¹å¾è¿‡æ»¤ã€äºšç»„è¯†åˆ«åŠç”Ÿç†å®¡è®¡"""
    # 1. ç»“å±€å˜é‡å¯¹é½
    df = df.rename(columns={'mortality_28d': 'mortality', 'composite_outcome': 'composite'})

    # 2. ä¸´åºŠç™½åå•è¿‡æ»¤ï¼šä¿ç•™å­—å…¸ç‰¹å¾ + æ ¸å¿ƒé…ç½®åˆ—
    allowed_cols = list(auditor_config.keys()) + ESSENTIAL_COLS
    df_cleaned = df[[c for c in allowed_cols if c in df.columns]].copy()
    
    print(f"ğŸ“‹ å®¡è®¡å¯åŠ¨: åŸå§‹ {df.shape[1]} åˆ— -> ç›®æ ‡ {df_cleaned.shape[1]} åˆ—")

    # 3. è¡ç”Ÿå˜é‡è®¡ç®—ï¼šè¯†åˆ«éè‚¾æŸä¼¤äºšç»„ (Scr < 1.5)
    if 'creatinine_max' in df_cleaned.columns:
        df_cleaned['subgroup_no_renal'] = (df_cleaned['creatinine_max'] < 1.5).astype(int)

    # 4. æ‰§è¡Œç”Ÿç†è§„åˆ™æ ¡éªŒ
    return audit_clinical_limits(df_cleaned, auditor_config)

def load_mimic_assets():
    """èµ„äº§åŠ è½½ï¼šè·å– MIMIC è®­ç»ƒé˜¶æ®µä¿å­˜çš„ Scalerã€Imputer åŠåæ€é…ç½®"""
    try:
        assets = {
            'scaler': joblib.load(os.path.join(ARTIFACT_DIR, "mimic_scaler.joblib")),
            'imputer': joblib.load(os.path.join(ARTIFACT_DIR, "mimic_mice_imputer.joblib")),
            'skewed_cols': joblib.load(os.path.join(ARTIFACT_DIR, "skewed_cols_config.pkl"))
        }
        print(f"âœ… MIMIC èµ„äº§åŠ è½½æˆåŠŸ (å« {len(assets['skewed_cols'])} ä¸ªåæ€ç‰¹å¾é…ç½®)")
        return assets
    except Exception as e:
        print(f"âŒ èµ„äº§åŠ è½½å¤±è´¥: {e}"); return None

def get_union_feature_config():
    """ç‰¹å¾å¹¶é›†æå–ï¼šæ•´åˆå¤šç»“å±€æ‰€éœ€çš„ç‰¹å¾æ¸…å•ï¼Œå¹¶åŒ¹é…ç”Ÿç†å®¡è®¡è§„åˆ™"""
    if not (os.path.exists(SELECTED_FEAT_PATH) and os.path.exists(DICT_PATH)):
        print("âŒ é”™è¯¯: é…ç½®æ–‡ä»¶ç¼ºå¤±"); return None

    # åŠ è½½ç»“å±€ç‰¹å¾æ¸…å•å’Œç”Ÿç†è§„åˆ™å­—å…¸
    with open(SELECTED_FEAT_PATH, 'r', encoding='utf-8') as f:
        selected_json = json.load(f)
    with open(DICT_PATH, 'r', encoding='utf-8') as f:
        full_physio_dict = json.load(f)

    # æå–æ‰€æœ‰ç»“å±€æ¶‰åŠçš„ç‰¹å¾å¹¶é›†
    union_features = {feat for target in selected_json.values() for feat in target['features']}
    
    # ä»…ä¿ç•™å¹¶é›†ç‰¹å¾çš„å®¡è®¡è§„åˆ™
    auditor_config = {k: v for k, v in full_physio_dict.items() if k in union_features}
    print(f"ğŸ¯ è¯†åˆ«åˆ° {len(union_features)} ä¸ªå”¯ä¸€ç‰¹å¾ï¼Œå·²åŒ¹é…å®¡è®¡è§„åˆ™")
    return auditor_config

def run_clinical_audit(df_raw, auditor_config):
    """ä¸´åºŠå®¡è®¡æ‰§è¡Œï¼šåº”ç”¨ç”Ÿç†è§„åˆ™è¿‡æ»¤ï¼Œå¹¶æ‰§è¡Œ 1%-99% ç»Ÿè®¡ç›–å¸½"""
    # 1. è°ƒç”¨ä¹‹å‰å®šä¹‰çš„å‡½æ•°å¼å®¡è®¡æµ
    df_audited = apply_clinical_audit_workflow(df_raw, auditor_config)
    
    # 2. ç»Ÿè®¡ç›–å¸½ (Winsorization)ï¼šæ¶ˆé™¤ 1% æå€¼æ³¢åŠ¨
    clinical_features = [c for c in df_audited.columns if c in auditor_config and c not in EXCLUDE_CLIPPING]
    
    clipped_count = 0
    for col in clinical_features:
        q = df_audited[col].quantile([0.01, 0.99])
        if q.isnull().any(): continue
        
        df_audited[col] = df_audited[col].clip(lower=q[0.01], upper=q[0.99])
        clipped_count += 1
    
    print(f"âœ… ç›–å¸½å¤„ç†å®Œæˆ: {clipped_count} ä¸ªä¸´åºŠç‰¹å¾å·²çº¦æŸ")
    return df_audited

def align_feature_space(df_audited, required_features):
    """ç©ºé—´å¯¹é½ï¼šç¡®ä¿ eICU åˆ—é¡ºåºä¸ MIMIC è®­ç»ƒæ—¶çš„ imputer æœŸå¾…å®Œå…¨ä¸€è‡´"""
    df_aligned = pd.DataFrame(index=df_audited.index)
    for col in required_features:
        if col in df_audited.columns:
            # è§£å†³é‡ååˆ—é˜²å¾¡ï¼šè‹¥å­˜åœ¨é‡ååˆ—åˆ™å–ç¬¬ä¸€åˆ—
            val = df_audited[col]
            df_aligned[col] = val.iloc[:, 0] if isinstance(val, pd.DataFrame) else val
        else:
            # eICU å®Œå…¨ç¼ºå¤±çš„åˆ—å¡« NaNï¼Œåç»­ç”± MICE æ’è¡¥
            df_aligned[col] = np.nan
    return df_aligned

def apply_mimic_transform(df_aligned, assets):
    """å˜æ¢åŒæ­¥ï¼šæ‰§è¡Œ Log å˜æ¢ã€MICE æ’è¡¥ä¸ Z-score æ ‡å‡†åŒ–"""
    imputer, scaler, skewed_cols = assets['imputer'], assets['scaler'], assets['skewed_cols']
    df_trans = df_aligned.copy()
    
    # 1. åæ€ç‰¹å¾åŒæ­¥ Log1p å˜æ¢
    for col in skewed_cols:
        if col in df_trans.columns:
            df_trans[col] = np.log1p(df_trans[col].clip(lower=0))
    
    # 2. æ‰§è¡Œ MIMIC æ²‰æ·€çš„ Transform ç®¡é“
    print("   æ‰§è¡Œ Transform (MICE + Scaler)...")
    imputed_data = imputer.transform(df_trans)
    return pd.DataFrame(
        scaler.transform(imputed_data),
        columns=imputer.feature_names_in_,
        index=df_aligned.index
    )

def audit_final_distribution(df):
    """åˆ†å¸ƒå®¡è®¡ï¼šæ£€æŸ¥å˜æ¢å Z-score æ˜¯å¦æ¥è¿‘æ ‡å‡†åˆ†å¸ƒ (Mean=0, Std=1)"""
    print("\nğŸ“ˆ å…³é”®ç‰¹å¾ (Z-score) å®¡è®¡:")
    for col in ['creatinine_max', 'lactate_max', 'pao2fio2ratio_min', 'ph_min']:
        if col in df.columns:
            print(f"   {col:<20}: Mean={df[col].mean():.3f} | Std={df[col].std():.3f}")

def generate_eicu_processed(target, df_audited, assets):
    """ç»“å±€ç”Ÿæˆï¼šé’ˆå¯¹ç‰¹å®š outcome ç”Ÿæˆå¯¹é½åçš„æ¨ç†æ•°æ®é›†"""
    print(f"\nğŸ› ï¸ å¤„ç†ç»“å±€: {target}")
    
    # 1. åŠ è½½å¯¹åº”ç»“å±€çš„ç‰¹å¾æ¸…å• (ä½¿ç”¨ SELECTED_FEAT_PATH)
    try:
        with open(SELECTED_FEAT_PATH, 'r') as f:
            selected_features = json.load(f)[target]["features"]
    except Exception as e:
        print(f"âŒ åŠ è½½ç‰¹å¾æ¸…å•å¤±è´¥: {e}"); return

    # 2. å¯¹é½ç‰¹å¾ç©ºé—´å¹¶æ‰§è¡Œ MIMIC è½¬æ¢
    df_aligned = align_feature_space(df_audited, assets['imputer'].feature_names_in_)
    df_scaled = apply_mimic_transform(df_aligned, assets)

    # 3. ç­›é€‰ç‰¹å¾å¹¶æ¢å¤ä¿æŠ¤åˆ— (Labels & Flags)
    df_final = df_scaled[[f for f in selected_features if f in df_scaled.columns]].copy()
    for col in PROTECTED_COLS:
        if col in df_audited.columns:
            source = df_audited[col]
            df_final[col] = (source.iloc[:, 0] if isinstance(source, pd.DataFrame) else source).fillna(0).astype(int).values

    # 4. åˆ†å¸ƒå®¡è®¡ä¸å¯¼å‡º
    audit_final_distribution(df_final)
    save_path = os.path.join(SAVE_DIR, f"eicu_processed_{target}.csv")
    df_final.to_csv(save_path, index=False)
    print(f"âœ… ä¿å­˜æ¨ç†é›†: {save_path}")

def main():
    print("="*60)
    print("ğŸš€ Module 09: eICU Preprocessing & Outcome Alignment")
    print("="*60)

    # 1. åˆå§‹åŒ–ï¼šåŠ è½½ MIMIC è®­ç»ƒèµ„äº§ä¸å¹¶é›†ç‰¹å¾è§„åˆ™
    assets = load_mimic_assets()
    auditor_config = get_union_feature_config()
    if not assets or not auditor_config:
        return

    # 2. æ•°æ®è¯»å–ï¼šåŠ è½½ eICU åŸå§‹é˜Ÿåˆ—
    if not os.path.exists(EICU_RAW_PATH):
        print(f"âŒ Error: Raw data not found at {EICU_RAW_PATH}")
        return
    
    df_raw = pd.read_csv(EICU_RAW_PATH)
    print(f"ğŸ“¦ Loaded eICU raw data: {df_raw.shape[0]} patients")
    
    # 3. ä¸´åºŠé¢„å¤„ç†ï¼šæ‰§è¡Œç”Ÿç†å®¡è®¡ã€å•ä½ä¿®å¤åŠ 1%-99% ç›–å¸½
    df_audited = run_clinical_audit(df_raw, auditor_config)

    # 4. å­˜æ¡£ä¸­é—´æ€ï¼šä¿å­˜æœªæ ‡å‡†åŒ–ä½†å·²æ¸…æ´—çš„ä¸´åºŠç‰ˆæœ¬ï¼ˆä¾¿äºåç»­éªŒè¯ï¼‰
    scale_save_path = os.path.join(SAVE_DIR, "eicu_raw_scale.csv")
    df_audited.to_csv(scale_save_path, index=False)
    print(f"â­ Clinical audited data saved: {scale_save_path}")

    # 5. å¤šç»“å±€å¯¹é½å¾ªç¯ï¼šç”Ÿæˆå„ç»“å±€ä¸“å±çš„ Z-score å¤„ç†é›†
    print("\nğŸ”„ Starting alignment & Z-score transformation...")
    for target in ['pof', 'mortality', 'composite']:
        generate_eicu_processed(target, df_audited, assets)

    print("\n" + "="*60)
    print("âœ… Module 09 Pipeline Completed Successfully!")
    print("="*60)

if __name__ == "__main__":
    main()
